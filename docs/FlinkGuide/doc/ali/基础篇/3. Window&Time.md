# window

Window 就是用来对一个无限的流设置一个有限的集合，在有界的数据集上进行操作的一种机制。window 又可以分为基于时间（Time-based）的 window 以及基于数量（Count-based）的 window

## Time window

### **tumbling time windows(翻滚时间窗口)**

### **sliding time windows(滑动时间窗口)**

## Count Windows

### tumbling count window 

###  sliding count window 

## window机制

到达window算子的数据由WindowAsiigner处理，它把数据分发到一个或者多个窗口(可能会新建窗口)。窗口其实就是数据列的一个标识符，可能包含一些例如TimeWindow的开始/结束时间的元数据信息。注意，一个数据是可以添加到多个窗口的。

每个窗口都有一个trigger,它决定窗口何时计算/清除。当注册的计时器超时，trigger被每个插入当前窗口的数据调用。对于每个事件，trigger可以决定触发(例如计算)，清除(删除窗口)或者触发并清除窗口。

当trigger触发，窗口内的数据可以交给一个可选的Evictor, 它可以决定删除最早进入窗口的一些数据。剩余的数据交给计算函数。

计算函数接受到窗口内的数据(可能经过了Evictor的过滤)并计算出结果。DataStream API接受例如sum()`, `min()`, `max(),  以及 `ReduceFunction`, `FoldFunction`, WindowFunction。

#  WindowAssigner, Evictor 以及 Trigger

## windowAssigner

window 方法接收的输入是一个WindowAssigner， WindowAssigner 负责将每条输入的数据分发到正确的 window 中（一条数据可能同时分发到多个 Window 中），Flink 提供了几种通用的 WindowAssigner：

1. tumbling window(窗口间的元素无重复），
2. sliding window（窗口间的元素可能重复），
3. session window 以及 global window。
4. 如果需要自己定制数据分发策略，则可以实现一个 class，继承自 WindowAssigner。

## evictor

evictor 主要用于做一些数据的自定义操作，可以在执行用户代码之前，也可以在执行用户代码之后

Flink 提供了如下三种通用的 evictor：

1.  CountEvictor 保留指定数量的元素
2. DeltaEvictor 通过执行用户给定的 DeltaFunction 以及预设的 threshold，判断是否删除一个元素。
3. TimeEvictor设定一个阈值 interval，删除所有不再 max_ts – interval 范围内的元素，其中 max_ts 是窗口内时间戳的最大值。

evictor 是可选的方法，如果用户不选择，则默认没有。

## trigger

trigger 用来判断一个窗口是否需要被触发，每个 WindowAssigner 都自带一个默认的 trigger，如果默认的 trigger 不能满足你的需求，则可以自定义一个类，继承自 Trigger 即可，我们详细描述下 Trigger 的接口以及含义：

1. onElement() 每次往 window 增加一个元素的时候都会触发
2. onEventTime() 当 event-time timer 被触发的时候会调用
3. onProcessingTime() 当 processing-time timer 被触发的时候会调用
4. onMerge() 对两个 trigger 的 state 进行 merge 操作
5. clear() window 销毁的时候被调用



上面的接口中前三个会返回一个 TriggerResult，TriggerResult 有如下几种可能的选择：

1. CONTINUE 不做任何事情

2. FIRE 触发 window
3. PURGE 清空整个 window 的元素并销毁窗口
4. FIRE_AND_PURGE 触发窗口，然后销毁窗口



# Time & Watermark

## Time

1. Event-Time 表示事件发生的时间，
2. Processing-Time 则表示处理消息的时间（墙上时间），
3. Ingestion-Time 表示进入到系统的时间。

设置方法

```scala
env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime); // 设置使用 ProcessingTime
```

## Watermark

我们可以考虑一个这样的例子：某 App 会记录用户的所有点击行为，并回传日志（在网络不好的情况下，先保存在本地，延后回传）。A 用户在 11:02 对 App 进行操作，B 用户在 11:03 操作了 App，但是 A 用户的网络不太稳定，回传日志延迟了，导致我们在服务端先接受到 B 用户 11:03 的消息，然后再接受到 A 用户 11:02 的消息，消息乱序了。

那我们怎么保证基于 event-time 的窗口在销毁的时候，已经处理完了所有的数据呢？这就是 watermark 的功能所在：

**watermark 会携带一个单调递增的时间戳 t，watermark(t) 表示所有时间戳不大于 t 的数据都已经到来了，未来小于等于t的数据不会再来，因此可以放心地触发和销毁窗口了.**

### 迟到的数据

上面的 watermark 让我们能够应对乱序的数据，但是真实世界中我们没法得到一个完美的 watermark 数值 — 要么没法获取到，要么耗费太大，因此实际工作中我们会使用近似 watermark — 生成 watermark(t) 之后，还有较小的概率接受到时间戳 t 之前的数据，在 Flink 中将这些数据定义为 “late elements”, 同样我们可以在 window 中指定是允许延迟的最大时间（默认为 0），可以使用下面的代码进行设置

## 状态存储

Window 中的状态存储。我们知道 Flink 是支持 Exactly Once 处理语义的，那么 Window 中的状态存储和普通的状态存储又有什么不一样的地方呢？

首先给出具体的答案：从接口上可以认为没有区别，但是每个 Window 会属于不同的 namespace，而非 Window 场景下，则都属于 VoidNamespace ，最终由 State/Checkpoint 来保证数据的 Exactly Once 语义

