由于流处理的计算逻辑是通过DAG图来表示的，因此它们的大部分API都是围绕构建这种计算逻辑图来设计的。

Apache Flink 的接口虽然也是在构建计算逻辑图，但是 Flink 的 API 定义更加面向数据本身的处理逻辑，它把数据流抽象成为一个无限集，然后定义了一组集合上的操作，然后在底层自动构建相应的 DAG 图

# API概览

## 流操作

Flink DataStream API 的核心，就是代表流数据的 DataStream 对象,整个计算逻辑图的构建就是围绕调用DataStream对象上的不同操作产生新的DataStream对象展开的。整体上分为四类操作：

1. 对单条记录的操作：filter 、 map
2. 对多条记录的操作：Window操作，将需要的记录关联到一起进行处理
3. 对多个流进行操作并转换为单个流：Union、Join、Connect。
4. 流拆分： Split

![image-20210529224240807](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210529224240807.png)

基本 DataStream 对象上的 allWindow 与 KeyedStream 上的 Window 操作都是对数据进行分组，但是 KeyBy 是在水平分向对流进行切分，而 Window 是在垂直方式对流进行切分。



使用 KeyBy 进行数据切分之后，后续算子的每一个实例可以只处理特定 Key 集合对应的数据。除了处理本身外，Flink 中允许算子维护一部分状态（State），在KeyedStream 算子的状态也是可以分布式存储的。由于 KeyBy 是一种确定的数据分配方式（下文将介绍其它分配方式），因此即使发生 Failover 作业重启，甚至发生了并发度的改变，Flink 都可以重新分配 Key 分组并保证处理某个 Key 的分组一定包含该 Key 的状态，从而保证一致性。

## 数据分组方式

- **Global:** 上游算子将所有记录发送给下游算子的第一个实例。
- **Broadcast:** 上游算子将每一条记录发送给下游算子的所有实例。
- **Forward：**只适用于上游算子实例数与下游算子相同时，每个上游算子实例将记录发送给下游算子对应的实例。
- **Shuffle：**上游算子对每条记录随机选择一个下游算子进行发送。
- **Rebalance：**上游算子通过轮询的方式发送数据。
- **Rescale：**当上游和下游算子的实例数为 n 或 m 时，如果 n < m，则每个上游实例向ceil(m/n)或floor(m/n)个下游实例轮询发送数据；如果 n > m，则 floor(n/m) 或 ceil(n/m) 个上游实例向下游实例轮询发送数据。
- **PartitionCustomer：**当上述内置分配方式不满足需求时，用户还可以选择自定义分组方式。

## 类型系统

在 Flink 底层，它是使用 TypeInformation 对象对类型进行描述的，TypeInformation 对象定义了一组类型相关的信息供序列化框架使用。

![image-20210529225234969](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210529225234969.png)

Flink 内置了一部分常用的基本类型，对于这些类型，Flink 也内置了它们的TypeInformation，用户一般可以直接使用而不需要额外的声明，Flink 自己可以通过类型推断机制识别出相应的类型。

在 Flink 中，一般 Java 接口采用 Tuple 类型来组合多个字段，而 Scala 则更经常使用 Row 类型或 Case Class

## env

如果我们在 IDE 中直接右键运行，则会创建 LocalStreamExecutionEnvironment 对象；如果是在一个实际的环境中，则会创建 RemoteStreamExecutionEnvironment 对象

## JobGraph

最后，我们对 DataStream API 的原理进行简要的介绍。当我们调用 DataStream#map 算法时，Flink 在底层会创建一个 Transformation 对象，这一对象就代表我们计算逻辑图中的节点。它其中就记录了我们传入的 MapFunction，也就是 UDF（User Define Function）。随着我们调用更多的方法，我们创建了更多的 DataStream 对象，每个对象在内部都有一个 Transformation 对象，这些对象根据计算依赖关系组成一个图结构，就是我们的计算图。后续 Flink 将对这个图结构进行进一步的转换，从而最终生成提交作业所需要的 JobGraph。

