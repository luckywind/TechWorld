# 调优
## 资源配置调优
### 并行度

1. 先压测计算每个并行度的处理上限，再根据业务计算所需并行度。
2. Source 端：数据源端是 Kafka，Source的并行度设置为Kafka对应Topic的分区数。
3. Transform 端：
   - Keyby 之前：一般较轻量，可以与Source 保持一致
   - Keyby 之后：建议设置为 2 的整数次幂
4. Sink 端：需要根据下游服务抗压能力设置




###RocksDB大状态
磁盘读为性能瓶颈：
使用内存结合磁盘的方式来存储数据，每次获取数据时，先从内存中 blockcache 中查找，如果内存中没有再去磁盘中查询，性能瓶颈主要在于 RocksDB 对磁盘的读请求，所以当处理性能不够时，仅需要横向扩展并行度即可提高整个Job 的吞吐量
1. RocksDB 多磁盘目录
2. 开启增量检查点：state.backend.incremental：，默认false，改为true
3. 增大内存cache：默认大小为 8 MB，建议设置到 64 ~ 256 MB，state.backend.rocksdb.block.cache-size， 提升缓存命中率
4. 本地恢复：当 Flink 任务失败时，可以基于本地的状态信息进行恢复任务，可能不需要从 hdfs 拉取数据

### Checkpoint 设置

1. 比较耗时的Checkpoint，可以降低频率，调大间隔

##反压处理
反压机制是指系统能够自己检测到被阻塞的 Operator，然后自适应地降低源头或上游数据的发送速率，从而维持整个系统的稳定。
###反压定位：
1. 通过Flink UI 的BackPressure 页面查看Task 的状态，HIGH 表示Task 被反压。
2. Task遇到瓶颈且导致上游 Task 受到反压的 Task 对应的 InputChannel 必然是满的。
###反压原因及处理
1. Flink 使用的主要是内存和CPU 资源，借助分析工具识别热线程

## 数据倾斜

### 判断是否倾斜

Flink Web UI 可以看到每个subtask 处理了多少数据，通常数据倾斜也会引起反压

### 解决倾斜

1. 强制shuffle，Keyby 之前就发生倾斜，一般是数据源本身就不均匀
2. keyBy 后的窗口聚合：两阶段聚合：
   -  第一阶段聚合：key拼接随机数前缀或后缀，进行keyby、开窗、聚合
   -  第二阶段聚合：去掉随机数前缀或后缀，按照原来的key及windowEnd作keyby、聚合

## KafkaSource 调优

1. 动态发现分区：FlinkKafkaConsumer 开启新分区动态发现

## FlinkSQL 调优

1. 聚合优化
   - 开启MiniBatch，缓存一定的数据后再触发处理，以减少对State的访问，从而提升吞吐并减少数据的输出量。
   - 开启LocalGlobal（解决常见数据热点问题）
   - 开启Split Distinct
2. TopN 优化
