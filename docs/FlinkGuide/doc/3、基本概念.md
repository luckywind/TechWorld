

# [基本概念](http://docs.api..net/flink/)

# Stream & Transformation & Operator

用户实现的Flink程序是由Stream和Transformation这两个基本构建块组成，其中Stream是一个中间结果数据，**而Transformation是一个操作，它对一个或多个输入Stream进行计算处理，输出一个或多个结果Stream**。
当一个Flink程序被执行的时候，它会被映射为Streaming Dataflow。一个Streaming Dataflow是由一组Stream和Transformation Operator组成，它类似于一个DAG图，在启动的时候从一个或多个Source Operator开始，结束于一个或多个Sink Operator。

下面是一个由Flink程序映射为Streaming Dataflow的示意图，如下所示：

![img](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/program_dataflow.svg)

上图中，FlinkKafkaConsumer是一个Source Operator，map、keyBy、timeWindow、apply是Transformation Operator，RollingSink是一个Sink Operator。

**Operator之间用Stream连起来**。

# Parallel Dataflow

在Flink中，程序天生是并行和分布式的：一个Stream可以被分成多个Stream分区（Stream Partitions），**一个Operator可以被分成多个Operator Subtask，每一个Operator Subtask是在不同的线程中独立执行的。**
**一个Operator的并行度，等于Operator Subtask的个数，一个Stream的并行度总是等于生成它的Operator的并行度。**

有关Parallel Dataflow的实例，如下图所示：

四个Operator(黄色圆圈)生成了三个Stream(灰色箭头)

![img](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/parallel_dataflow.svg)

上图Streaming Dataflow的并行视图中，展现了在两个Operator之间的**Stream的两种模式**：

## One-to-one模式

比如从Source[1]到map()[1]，它保持了Source的**分区特性**（Partitioning）和分区内元素处理的**有序性**，也就是说map()[1]的Subtask看到数据流中记录的顺序，与Source[1]中看到的记录顺序是一致的。

## Redistribution模式

这种模式改变了输入数据流的分区，比如从map()[1]、map()[2]到keyBy()/window()/apply()[1]、keyBy()/window()/apply()[2]，上游的Subtask向下游的多个不同的Subtask发送数据，改变了数据流的分区，这与实际应用所选择的Operator有关系。

另外，Source Operator对应2个Subtask，所以并行度为2，而Sink Operator的Subtask只有1个，故而并行度为1。

# Task & Operator Chain

在Flink分布式执行环境中，会将多个Operator Subtask串起来组成一个Operator Chain，实际上就是一个执行链，每个执行链会在TaskManager上一个独立的线程中执行，如下图所示：

![img](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/tasks_chains.svg)

上图中上半部分表示的是一个Operator Chain，多个Operator通过Stream连接，而每个Operator在运行时对应一个Task；图中下半部分是上半部分的一个并行版本，也就是对每一个Task都并行化为多个Subtask。

# Windows

在流处理应用中，数据是连续不断的，因此我们不可能等到所有数据都到了才开始处理。当然我们可以每来一个消息就处理一次，但是有时我们需要做一些聚合类的处理，例如：在过去的1分钟内有多少用户点击了我们的网页。在这种情况下，我们必须定义一个窗口，用来收集最近一分钟内的数据，并对这个窗口内的数据进行计算。

窗口可以是时间驱动的（Time Window，例如：每30秒钟），也可以是数据驱动的（Count Window，例如：每一百个元素）。一种经典的窗口分类可以分成：翻滚窗口（Tumbling Window，无重叠），滚动窗口（Sliding Window，有重叠），和会话窗口（Session Window，活动间隙）。

![img](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/windows.png)

# Time

Flink 在流程序中支持不同的 Time 概念:

![img](3、基本概念.assets/event_ingestion_processing_time.svg)

## Processing Time

**Processing Time 是指事件被处理时机器的系统时间**。当流程序在 Processing Time 上运行时，所有基于时间的操作(如时间窗口)将使用当时机器的系统时间。
Processing Time 是最简单的 "Time" 概念，不需要流和机器之间的协调，它提供了最好的性能和最低的延迟。但是，在分布式和异步的环境下，Processing Time **不能提供确定性，因为它容易受到事件到达系统的速度（例如从消息队列）、事件在系统内操作流动的速度以及中断的影响。**

## Event Time

**Event Time 是事件发生的时间，一般就是数据本身携带的时间**。这个时间通常是在事件到达 Flink 之前就确定的，并且可以从每个事件中获取到事件时间戳。在 Event Time 中，时间取决于数据，而跟其他没什么关系。
**Event Time 程序必须指定如何生成 Event Time 水印，这是表示 Event Time 进度的机制。**

## Ingestion Time

**Ingestion Time 是事件进入 Flink 的时间**。在源操作处，每个事件将源的当前时间作为时间戳，**并且基于时间的操作（如时间窗口）会利用这个时间戳。**
Ingestion Time 在概念上位于 Event Time 和 Processing Time 之间。 与 Processing Time 相比，它稍微贵一些，但结果更可预测。因为 Ingestion Time 使用稳定的时间戳（在源处分配一次），所以对事件的不同窗口操作将引用相同的时间戳，而在 Processing Time 中，每个窗口操作符可以将事件分配给不同的窗口（基于机器系统时间和到达延迟）(一个事件在不同的窗口中，它的Processing Time不一样？)。
与 Event Time 相比，Ingestion Time 程序(通常是Source Operator? )无法处理任何无序事件或延迟数据，但程序不必指定如何生成水印。

# 有状态的数据操作

## state

状态是计算过程中的数据信息，在容错恢复和Checkpoint 中有重要的作用，流计算在本质上是Incremental Processing，因此需要不断查询保持状态；另外，为了确保Exactly- once 语义，需要数据能够写入到状态中；而持久化存储，能够保证在整个分布式系统运行失败或者挂掉的情况下做到Exactly- once，这是状态的另外一个价值。

![img](3、基本概念.assets/state_partitioning.svg)

在流处理中，有些操作仅仅在某一时间针对单一事件（如事件转换map），有些操作需要记住多个事件的信息并进行处理（window operators）,后者的这些操作称为有状态的操作。
有状态的操作一般被维护在内置的key/value存储中。这些状态信息会跟数据流一起分区并且分布存储，并且可以通过有状态的数据操作来访问。**因此这些key/value的状态信息仅在带key的数据流（通过keyBy() 函数处理过）中才能访问到。数据流按照key排列能保证所有的状态更新都是本地操作，保证一致性且无事务问题。同时这种排列方式使Flink能够透明的再分发状态信息和调整数据流分区。**

# 容错/Checkpoint

![img](3、基本概念.assets/stream_barriers.svg)

Flink 通过流回放和设置检查点的方式实现容错。**一个checkpoint关联了输入流中的某个记录和相应状态和操作**(checkpoint三元组：记录，状态，操作？)。数据流可以从checkpoint中进行恢复，并保证一致性（exactly-once 的处理语义）。 Checkpoint的间隔关系到执行时的容错性和恢复时间。

[小米](http://docs.api..net/flink/flink/flink-glossary.html)

# API

API 通常分为三层，由上而下可分为SQL / Table API、DataStream API、ProcessFunction 三层，API 的表达能力及业务抽象能力都非常强大，但越接近SQL 层，表达能力会逐步减弱，抽象能力会增强，反之，ProcessFunction 层API 的表达能力非常强，可以进行多种灵活方便的操作，但抽象能力也相对越小。

