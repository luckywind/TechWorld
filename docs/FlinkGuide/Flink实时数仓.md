dwm

what?

明细层dwd和服务层dws的中间层

why?

多个dws可能依赖相同的dwd，而且处理逻辑相同，为了避免重复处理，使用dwm来保存共同的加工操作。

dws

方便查询



clickHouse存储dws层的数据

实时数仓中这些表存储在哪？

敲三遍代码：

1. 整理思路->对着代码敲
2. 保留注释删除代码，对着注释敲
3. 自己敲



**普通的实时计算**优先考虑时效性，所以从数据源采集经过实时计算直接得到结果。如此 做时效性更好，但是弊端是由于计算过程中的中间结果没有沉淀下来，所以当面对大量实时 需求的时候，计算的复用性较差，开发成本随着需求增加直线上升。

**实时数仓**基于一定的数据仓库理念，对数据处理流程进行规划、分层，目的是提高数据 的复用性。

分层

- ODS:原始数据，日志和业务数据，使用FlinkCDC把数据统一写入一个Topic

- DWD:根据数据对象为单位进行分流，比如订单、页面访问等等

​		从Kafka中读取ODS中将事实数据分流写会Kafka的多个Topic作为业务数据的dwd层，纬度数据保存到HBase。但是如果要新增事实表，如果要不改程序代码，就需要动态分流技术

> 动态分流：Mysql维护配置，使用 FlinkCDC 读取配置信息表，将配置流作为广播流与主流进行连接。
>
> <img src="https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image-20250416094311888.png" alt="image-20250416094311888" style="zoom:50%;" />

- DIM:维度数据
  纬度数据一般通过主键查询的数据库比如 HBase,Redis,MySQL 等。一般把事实数据写入流中，进行进一步处理，最终形成宽表。

- DWM:对于部分数据对象进行进一步加工，比如独立访问、跳出行为，也可以和维度 进行关联，形成宽表，依旧是明细数据。

- DWS:根据某个主题将多个事实数据轻度聚合，形成主题宽表。 ADS:把ClickHouse中的数据根据可视化需进行筛选聚合

![image-20250416092332508](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image-20250416092332508.png)





优化

1. 资源配置调优
   并行度计算：压测单个并行度的处理上限，qps/单并行上限=并行度，可以乘以1.2富余一些资源

2. Source端并行度
   Flink 的一个并行度可以处理一至多个分区的数据，如果并行度多于 Kafka 的分区数，会造成有的并行度空闲

3. Sink端并行度
   根据下游服务的抗压能力进行评估

4. Checkpoint设置

   间隔根据任务耗时情况设置为分钟级别，中间暂停4到8分钟

5. 数据倾斜

   - keyBy前倾斜

     让 Flink 任务强制进行 shuffle。使用 shuffle、rebalance 或 rescale

   - keyBy后倾斜





实时需求种类

1. 实时报表
2. 实时数据大屏监控
3. 数据预警
4. 实时推荐