# 窗口函数

[spark-sql](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-window.html)

窗口函数操作一个行组（窗口），基于该行组针对每一行返回一个值。

语法

```sql
窗口函数 [ nulls_option ] OVER
( [  { PARTITION | DISTRIBUTE } BY partition_col_name = partition_col_val ( [ , ... ] ) ]  -- 可选分组
  { ORDER | SORT } BY expression [ ASC | DESC ] [ NULLS { FIRST | LAST } ] [ , ... ]       -- 排序
  [ window_frame ] )   -- 窗口表达式
```



**1. 窗口函数**

- 秩函数

  **Syntax:** `row_number() / rank() / dense_rank()`

- 分布函数：percent_rank() / cume_dist()

- 分析函数

  **Syntax:** `CUME_DIST | LAG | LEAD | NTH_VALUE | FIRST_VALUE | LAST_VALUE`

- 聚合函数

  **Syntax:** `MAX | MIN | COUNT | SUM | AVG | ...`

2. **nulls_option 是否跳过null值**

   - RESPECT NULLS 不跳过(默认)

   - IGNORE NULLS   

     > 只有LAG | LEAD | NTH_VALUE | FIRST_VALUE | LAST_VALUE可以使用

3. **over()**  <font color=red>定义一个窗口</font>
  
   **用来指定函数执行的窗口范围，这个数据窗口大小默认会随着行的变化而变化，因为frame_end默认是当前行；**
   
   如果括号中什么都不写，则意味着窗口包含满足WHERE条件的所有行，窗口函数基于所有行进行计算
   
3. **窗口表达式**
   { RANGE | ROWS } { frame_start | BETWEEN frame_start AND frame_end }

   > 指定窗口开始，默认当前行结束
   >
   > 也可以用between指定开始和结束

​    窗口起止表达式

UNBOUNDED PRECEDING | offset PRECEDING | CURRENT ROW | offset FOLLOWING | UNBOUNDED FOLLOWING

> 开始和结束如何

frame_end默认是当前行



## 数据构造

```sql
with orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
)

select * from orders;



也可以创建一个临时表
create temporary view orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
)
```

## 设置窗口的方法

### over定义窗口

over后面是窗口，可以使用()定义，也可以在from子句中通过window关键字定义窗口

### order by 

1. <font color=red>在from子句里通过window关键字后面接窗口别名并定义窗口，多个窗口用逗号隔开</font>。如果SQL中涉及的窗口较多,采用别名可以看起来更清晰易读
2. order by 意味着逐行加入并产生聚合结果

```sql
with orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
)
select *, sum(cost) over mywindow as `累计`
from orders
window mywindow as (order by orderdate);
```

只有order by 子句，则在整个数据集里排序，<font color=red>**序号**</font>相同的进行聚合追加到行尾，并逐步累加

| name | orderdate  | cost | 累计                                                         |      |
| ---- | ---------- | ---- | ------------------------------------------------------------ | ---- |
| jack | 2017-01-01 | 10   | 25                                                           |      |
| tony | 2017-01-01 | 15   | <font color=red>25,注意这个值和上面的一样，<br>因为, order 的序号一样，按序号聚合的</font> |      |
| jack | 2017-01-02 | 23   | 48                                                           |      |
| tony | 2017-01-04 | 29   | 77                                                           |      |
| jack | 2017-01-07 | 46   | 123                                                          |      |
| jack | 2017-01-08 | 42   | 165                                                          |      |
| tony | 2017-02-03 | 50   | 215                                                          |      |
| jack | 2017-04-06 | 55   | 270                                                          |      |
| mart | 2017-04-08 | 62   | 332                                                          |      |
| mart | 2017-04-09 | 68   | 400                                                          |      |

### partition by 

窗口函数在不同的分组上分别执行

```sql
with orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
)
select *,
sum(cost) over windowByName as `不带order`,
sum(cost) over windowByNameOrderbyDate as `带order`
from orders
window 
 windowByName as (partition by name),
 windowByNameOrderbyDate as (partition by name order by orderdate);
```

注意两个窗口上，聚合函数的表现：

1. 不带order，则在每个分组里聚合当前组，每行结果一样
2. 带order, 也是分别在每个组里聚合，但是逐步聚合到当前ROW，每行结果不一样

| name | orderdate  | cost | 不带order | 带order |      |
| ---- | ---------- | ---- | --------- | ------- | ---- |
| mart | 2017-04-08 | 62   | 205       | 62      |      |
| mart | 2017-04-09 | 68   | 205       | 130     |      |
| mart | 2017-05-10 | 75   | 205       | 205     |      |
| jack | 2017-01-01 | 10   | 176       | 10      |      |
| jack | 2017-01-02 | 23   | 176       | 33      |      |
| jack | 2017-01-07 | 46   | 176       | 79      |      |
| jack | 2017-01-08 | 42   | 176       | 121     |      |
| jack | 2017-04-06 | 55   | 176       | 176     |      |
| tony | 2017-01-01 | 15   | 94        | 15      |      |
| tony | 2017-01-04 | 29   | 94        | 44      |      |
| tony | 2017-02-03 | 50   | 94        | 94      |      |

### 向前的窗口

<font color=red>ROWS 行数 PRECEDING</font>

```sql
with orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
)
select *, sum(cost) over(order by orderdate ROWS 1 PRECEDING) as `和前一项累计`
from orders;
```



| name | orderdate  | cost | `和前一项累计` |      |
| ---- | ---------- | ---- | -------------- | ---- |
| jack | 2017-01-01 | 10   | 10             |      |
| tony | 2017-01-01 | 15   | 25             |      |
| jack | 2017-01-02 | 23   | 38             |      |
| tony | 2017-01-04 | 29   | 52             |      |
| jack | 2017-01-07 | 46   | 75             |      |
| jack | 2017-01-08 | 42   | 88             |      |
| tony | 2017-02-03 | 50   | 92             |      |
| jack | 2017-04-06 | 55   | 105            |      |
| mart | 2017-04-08 | 62   | 117            |      |
| mart | 2017-04-09 | 68   | 130            |      |
| neil | 2017-04-11 | 12   | 80             |      |
| mart | 2017-05-10 | 75   | 87             |      |



### 向后的窗口

<font color=red>ROWS between current row and  向后的行数 FOLLOWING</font>

```sql
with orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
)
select *, sum(cost) over(order by orderdate ROWS between current row and   1 FOLLOWING) as `向后一行聚合`
from orders;
```

| name | orderdate  | cost | 向后一行聚合 |      |
| ---- | ---------- | ---- | ------------ | ---- |
| jack | 2017-01-01 | 10   | 25           |      |
| tony | 2017-01-01 | 15   | 38           |      |
| jack | 2017-01-02 | 23   | 52           |      |
| tony | 2017-01-04 | 29   | 75           |      |
| jack | 2017-01-07 | 46   | 88           |      |
| jack | 2017-01-08 | 42   | 92           |      |
| tony | 2017-02-03 | 50   | 105          |      |
| jack | 2017-04-06 | 55   | 117          |      |
| mart | 2017-04-08 | 62   | 130          |      |
| mart | 2017-04-09 | 68   | 80           |      |
| neil | 2017-04-11 | 12   | 87           |      |
| mart | 2017-05-10 | 75   | 75           |      |





```sql
select sum(cost) over(order by orderdate ROWS 1 PRECEDING) from orders;
自身+上1条记录
SUM(sale_price) over(order by product_id rows 1 following) 
自身+下1条记录
SUM(sale_price) over(order by product_id rows between 1 preceding and 2 following) 
自身+上1条记录+下2条记录
sum(cost) over() as sample1,--所有行相加
sum(cost) over(partition by name) as sample2,--按name 分组，组内数据相加
sum(cost) over(partition by name order by orderdate) as sample3,--按name分组并按orderdate排序（这里注意，一次累加的是下一个orderdate的所有数据），组内数据累加
sum(cost) over(partition by name order by orderdate rows between unbounded preceding  and current row) as sample4, --和sample3一样，由起点到当前行的聚合
sum(cost) over(partition by name order by orderdate rows between 1 preceding and current row) as sample5,--当前行和前面一行做聚合
sum(cost) over(partition by name order by orderdate rows between 1 preceding and 1 following )as sample6,--当前行和前一行及后面一行
sum(cost) over(partition by name order by orderdate rows between current row and unbounded following) as sample7 --当前行及后面所有行
from order1;
```



## 实际问题

### 用户行为分析

[参考](https://blog.csdn.net/SHWAITME/article/details/136095314)

```sql
with tracking_log as (
  select stack(
  4,
  001,'A','2020-01-01 12:01:44',
  001,'B','2020-01-01 12:01:44',
  002,'C','2020-02-01 12:01:44',
  002,'A','2020-02-03 12:01:44'
  )as (user_id,opr_id,log_time)
)
```

问题：

1）统计**每天**符合以下条件的用户数：A操作之后是B操作，AB操作必须相邻

> 注意看题，每天，同一个用户，AB操作相邻

```sql
--set spark.sql.legacy.timeParserPolicy=LEGACY;
create temporary view tracking_log as (
  select stack(
  4,
  001,'A','2020-01-01 12:01:44',
  001,'B','2020-01-01 12:02:44',
  002,'C','2020-02-01 11:01:44',
  002,'A','2020-02-03 12:02:44'
  )as (user_id,opr_id,log_time)
);

select 
    dt,
    count(distinct user_id) as res_cnt
from (
    select
        user_id,
        date_format(log_time,"yyMMdd") as dt,
        opr_id as curr_opr, -- 当前操作
        lead(opr_id,1) over(partition by user_id,date_format(log_time,"yyMMdd") order by log_time) as next_opr -- 获取 下一个操作
    from tracking_log
) res 
where curr_opr = "A" and next_opr="B" 
group by dt


法二：

select
    date_format(log_time, 'yyyy-MM-dd') as dt,
    count(distinct user_id) cnt
from
        (  select
              user_id,
              opr_id,
              log_time,
              collect_list(opr_id) over (partition by user_id order by log_time)  cs,
              -- 用户行为轨迹,把轨迹按照时间顺序拼接起来
              concat_ws(',', collect_list(opr_id) over (partition by user_id order by log_time)) as op_id_str
          from tracking_log
          order by user_id, log_time  ) t
where locate('A,B', op_id_str) >0 -- 查找字符串索引（从1开始）
group by date_format(log_time, 'yyyy-MM-dd')          

```

2）统计用户行为序列为A-B-D的用户数,其中:A-B之间可以有任何其他浏览记录(如C,E等),B-D之间除了C记录可以有任何其他浏览记录(如A,E等)

> 这其实是考察正则表达式写法

```sql
--set spark.sql.legacy.timeParserPolicy=LEGACY;
with tracking_log as (
  select stack(
  4,
  001,'A','2020-01-01 12:01:44',
  001,'B','2020-01-01 12:02:44',
  002,'C','2020-02-01 11:01:44',
  002,'A','2020-02-03 12:02:44'
  )as (user_id,opr_id,log_time)
)
select 
    date_format(log_time, 'yyyy-MM-dd') as dt,
    count(distinct user_id) cnt
from      (  select
              user_id,
              opr_id,
              log_time,
              collect_list(opr_id) over (partition by user_id order by log_time)  cs,
              -- 用户行为轨迹,把轨迹按照时间顺序拼接起来
              concat_ws(',', collect_list(opr_id) over (partition by user_id order by log_time)) as op_id_str
          from tracking_log
          order by user_id, log_time  ) t
where op_id_str like '%A%B%D%' and op_id_str not like '%A%B%C%D%'
group by   date_format(log_time, 'yyyy-MM-dd');

```

### 学生成绩分析

```sql
create temporary view  t as (
  select stack(
  4,
  001,1,60,
  001,2,75,
  002,2,33,
  002,3,97
  )as (student_id,course_id,grade)
);
```

1）查询每位学生获得的最高成绩和它所对应的科目，若科目成绩并列，取 course_id 最小的一门。查询结果需按 student_id 增序进行排序。

```sql
法一： 对成绩排序编号，按编号筛选
select 
 student_id,
 course_id,
 grade
from (
 select
  student_id,
  course_id,
  grade,
  row_number() over(partition by student_id order by grade desc,course_id asc) as rank_num 
 from t 
) res 
where rank_num = 1 
order by student_id 
```

法二：求每个学生成绩最大值，按成绩最大值筛选， group 两次

```sql
with t as (
  select stack(
  4,
  001,1,60,
  001,2,75,
  002,2,33,
  002,3,97
  )as (student_id,course_id,grade)
)
select 
student_id, `最高成绩`, min(course_id)
from (
  select 
  *,
  max(grade)over(partition by student_id) `最高成绩`
  from t 
)
where grade=`最高成绩`
group by student_id,`最高成绩`
```

2）查询每一科目成绩最高和最低分数的学生,输出course_id,student_id,score

我们可以按科目查找成绩最高的同学和最低分的同学，然后利用union连接起来

```sql
with t as (
  select stack(
  4,
  001,1,60,
  001,2,75,
  002,2,33,
  002,3,97
  )as (s_id,c_id,s_score)
)
select 
 c_id,
 s_id
from(
 select 
  *,
  row_number() over(partition by c_id order by s_score desc) r
 from t
) a
where r = 1
 
union
 
select 
 c_id,
 s_id
from(
 select 
  *,
  row_number() over(partition by c_id order by s_score) r
 from t
) a
where r = 1;


```



```sql

SELECT
student_id,course_id,grade
from (
SELECT
student_id,
course_id,grade,
rank() over(partition by course_id order by grade desc) as rk_1,
rank() over(partition by course_id order by grade ) as rk_2
from t 
)
where rk_1=1 or rk_2=1;
```







# 分析函数



[参考](http://lxw1234.com/archives/tag/hive-window-functions)

id,name,company_name,job_name, entry_time,leave_time

```sql
insert overwrite table tmp.asume
values 
(1, '张三', '华为','数据研发',20171011,20181001) ,
(1, '张三', '华为','数据研发',20181011,20191030) ,
(1, '张三', '华为','后台研发',20191031,20201101) ,
(1, '张三', '阿里','数据研发',20201105,20211003) ,
(1, '张三', '华为','后台研发',20211004,20211127),
(2, '李四', '华为','数据研发',20181011,20191029) ,
(2, '李四', 'oppo','数据研发',20191101,null) 
;
```



## lag  上面的

LAG(col,n,DEFAULT) 用于统计窗口内往上第n行值
参数1为列名，参数2为往上第n行（可选，默认为1），参数3为默认值（当往上第n行为NULL时候，取默认值，如不指定，则为NULL）

```sql
create temporary view  orders as (
  select stack(
  12,
  'jack','2017-01-01',10,
  'tony','2017-01-01',15,
  'jack','2017-01-02',23,
  'tony','2017-01-04',29,
  'jack','2017-01-07',46,
  'jack','2017-01-08',42,
  'tony','2017-02-03',50,
  'jack','2017-04-06',55,
  'mart','2017-04-08',62,
  'mart','2017-04-09',68,
  'neil','2017-04-11',12,
  'mart','2017-05-10',75
  )as (name,orderdate,cost)
);

select *, 
 lag(cost)  over(PARTITION by name order  by  orderdate ) as `lagcost`,
lead(cost)  over(PARTITION by name order  by  orderdate ) as lead_cost
from orders;
```



| name | orderdate  | cost | lagcost | lead_cost |      |
| ---- | ---------- | ---- | ------- | --------- | ---- |
| mart | 2017-04-08 | 62   |         | 68        |      |
| mart | 2017-04-09 | 68   | 62      | 75        |      |
| mart | 2017-05-10 | 75   | 68      |           |      |
| jack | 2017-01-01 | 10   |         | 23        |      |
| jack | 2017-01-02 | 23   | 10      | 46        |      |
| jack | 2017-01-07 | 46   | 23      | 42        |      |
| jack | 2017-01-08 | 42   | 46      | 55        |      |
| jack | 2017-04-06 | 55   | 42      |           |      |
| tony | 2017-01-01 | 15   |         | 29        |      |
| tony | 2017-01-04 | 29   | 15      | 50        |      |
| tony | 2017-02-03 | 50   | 29      |           |      |
| neil | 2017-04-11 | 12   |         |           |      |

## lead  下面的

与LAG相反
LEAD(col,n,DEFAULT) 用于统计窗口内往下第n行值
参数1为列名，参数2为往下第n行（可选，默认为1），参数3为默认值（当往下第n行为NULL时候，取默认值，如不指定，则为NULL）

### 网页停留时长

[参考](https://blog.csdn.net/kent7306/article/details/50441967)

用户Peter在浏览网页，在某个时刻，Peter点进了某个页面，过一段时间后，Peter又进入了另外一个页面，如此反复，那怎么去统计Peter在某个特定网页的停留时间呢，又或是怎么统计某个网页用户停留的总时间呢？

```sql
create temporary view user_log as (
  select stack(
  10,
"Peter","2015-10-12 01:10:00","url1",
"Peter","2015-10-12 01:15:10","url2",
"Peter","2015-10-12 01:16:40","url3",
"Peter","2015-10-12 02:13:00","url4",
"Peter","2015-10-12 03:14:30","url5",
"Marry","2015-11-12 01:10:00","url1",
"Marry","2015-11-12 01:15:10","url2",
"Marry","2015-11-12 01:16:40","url3",
"Marry","2015-11-12 02:13:00","url4",
"Marry","2015-11-12 03:14:30","url5"
  )as (userid,time,url)
);
select * from user_log;
```

分析步骤:

1. 获取用户在某个页面停留的起始与结束时间

   > 这里按时间排序后，下一个url的time就是当前url的离开时间，用到lead()函数

2. 结束-开始，得到停留时长

3. 计算用户在每个页面的总停留时长

```sql
with user_log as (
  select stack(
  10,
"Peter","2015-10-12 01:10:00","url1",
"Peter","2015-10-12 01:15:10","url2",
"Peter","2015-10-12 01:16:40","url3",
"Peter","2015-10-12 02:13:00","url4",
"Peter","2015-10-12 03:14:30","url5",
"Marry","2015-11-12 01:10:00","url1",
"Marry","2015-11-12 01:15:10","url2",
"Marry","2015-11-12 01:16:40","url3",
"Marry","2015-11-12 02:13:00","url4",
"Marry","2015-11-12 03:14:30","url5"
  )as (userid,time,url)
),

a as (
select userid,url, time as stime, -- 开始时间
  lead(time) over(partition by userid order by time) as etime,-- 离开时间
  UNIX_TIMESTAMP(lead(time) over(partition by userid order by time),'yyyy-MM-dd HH:mm:ss')- UNIX_TIMESTAMP(time,'yyyy-MM-dd HH:mm:ss') period  -- 停留时长
  from user_log
)
select userid,url, sum(period) `总停留时长` from a  
group by userid , url 
order by userid;
```



| userid | url  | 总停留时长 |      |
| ------ | ---- | ---------- | ---- |
| Marry  | url1 | 310        |      |
| Marry  | url2 | 90         |      |
| Marry  | url3 | 3380       |      |
| Marry  | url4 | 3690       |      |
| Marry  | url5 |            |      |
| Peter  | url1 | 310        |      |
| Peter  | url2 | 90         |      |
| Peter  | url3 | 3380       |      |
| Peter  | url4 | 3690       |      |
| Peter  | url5 |            |      |







## first_value

取分组内排序后，截止到当前行，第一个值

```sql
first_value(cost)  over(PARTITION by name  ) as fist,
last_value(cost)  over(PARTITION by name  ) as last
```



## Last_value

取分组内排序后，截止到当前行，最后一个值

## grouping sets

在一个GROUP BY查询中，根据不同的维度组合进行聚合，等价于将不同维度的GROUP BY结果集进行UNION ALL

```sql
SELECT 
month,
day,
COUNT(DISTINCT cookieid) AS uv,
GROUPING__ID 
FROM lxw1234 
GROUP BY month,day 
GROUPING SETS (month,day) 
ORDER BY GROUPING__ID;
```



```sql
with software_projects as (
  select stack(
7,
'pl', 'Scala' ,10,
'pl', 'Java ' ,1,
'pl', 'C++  ' ,2,
'us', 'Scala' ,15,
'us', 'Java ' ,3,
'fr', 'Scala' ,5,
'fr', 'Java ' ,9
  )as (country, language, projects_number)
)
SELECT country, language, SUM(projects_number) FROM software_projects 
GROUP BY
    GROUPING SETS ((country, language), (country), (language));
pl      Scala   10
us      Scala   15
fr      Scala   5
pl      C++     2
fr      Java    9
us      Java    3
pl      Java    1
us      NULL    18
fr      NULL    14
pl      NULL    13
NULL    Java    13
NULL    C++     2
NULL    Scala   30    
```



## cube

根据GROUP BY的维度的所有组合进行聚合。

## rollup

是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合。



# 案例

## 案例1

### lag

找到每个员工的当前公司与上一段经历的公司

```sql
select id, name,company_name,
lag(company_name)over(partition by id order by entry_time) last_company_name
from tmp.asume;
| id  | name  | company_name  | last_company_name  |
+-----+-------+---------------+--------------------+--+
| 1   | 张三    | 华为            | NULL               |
| 1   | 张三    | 华为            | 华为                 |
| 1   | 张三    | 华为            | 华为                 |
| 1   | 张三    | 阿里            | 华为                 |
| 1   | 张三    | 华为            | 阿里                 |
| 2   | 李四    | 华为            | NULL               |
| 2   | 李四    | oppo          | 华为                 |
+-----+-------+---------------+--------------------+--+
```

找到每个员工当前公司与上家公司

```sql
select id, name,company_name,last_company_name from 
(
  select id, name,company_name,
lag(company_name)over(partition by id,company_name order by entry_time) last_company_name
from tmp.asume
)
group by id, name,company_name,last_company_name
;
| id  | name  | company_name  | last_company_name  |
+-----+-------+---------------+--------------------+--+
| 2   | 李四    | 华为            | NULL               |
| 2   | 李四    | oppo          | NULL               |
| 1   | 张三    | 华为            | NULL               |
| 1   | 张三    | 华为            | 华为                 |
| 1   | 张三    | 阿里            | NULL               |
+-----+-------+---------------+--------------------+--+
```

### first_value

```sql
select id, name,company_name,
row_number()over(partition by id order by entry_time) rn,
first_value(company_name)over(partition by id order by entry_time) first_value
from tmp.asume;
```

# 参考

[Hive SQL 大厂必考常用窗口函数](https://mp.weixin.qq.com/s/cT09A3l8-6gMRgRLXmWEQg)

# 分组topN

分数相同的并列排名，注意用dense_rank()

方式一：窗口函数

```sql
create temporary view  Table1 as (
  select stack(
  8,
1 ,"AAAA","C1",67,
2 ,"BBBB","C1",55,
3 ,"CCCC","C1",67,
4 ,"DDDD","C1",65,
5 ,"EEEE","C1",95,
6 ,"FFFF","C2",57,
7 ,"GGGG","C2",87,
8 ,"HHHH","C2",74
  )as (id ,SName ,ClsNo ,Score)
);

select id,ClsNo,SName,Score from (
  select *, 
  dense_rank()over(partition by ClsNo order by Score desc) rk 
  from Table1 )
where rk<=3
order by ClsNo,Score desc;
```

方式二：

```sql
with Table1 as (
  select stack(
  8,
1 ,"AAAA","C1",67,
2 ,"BBBB","C1",55,
3 ,"CCCC","C1",67,
4 ,"DDDD","C1",65,
5 ,"EEEE","C1",95,
6 ,"FFFF","C2",57,
7 ,"GGGG","C2",87,
8 ,"HHHH","C2",74
  )as (id ,SName ,ClsNo ,Score)
)
select a.id,a.SName,a.ClsNo,a.Score
from Table1 a left join Table1 b on a.ClsNo=b.ClsNo and a.Score<b.Score
group by a.id,a.SName,a.ClsNo,a.Score
having count(distinct b.id)<=2
order by a.ClsNo,a.Score desc;
```

