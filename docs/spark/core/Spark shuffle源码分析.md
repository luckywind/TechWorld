å‚è€ƒ[Sparkæºç è§£è¯»ä¹‹ShuffleåŸç†å‰–æä¸æºç åˆ†æ](https://blog.csdn.net/qq_37142346/article/details/81875249)

[åä¸ºäº‘-shuffleåŸç†](https://www.cnblogs.com/weiyiming007/p/11244192.html)

ä»Spark-2.0.0å¼€å§‹ï¼ŒSpark æŠŠ Hash Shuffle ç§»é™¤ï¼Œå¯ä»¥è¯´ç›®å‰ Spark-2.0 ä¸­åªæœ‰ä¸€ç§ Shuffleï¼Œå³ä¸º Sort Shuffleã€‚æœ¬æ–‡è¯¦ç»†åˆ†æSortShuffleManagerçš„å®ç°åŸç†

# SortShuffleManager

è®°å½•æŒ‰ç…§ç›®æ ‡åˆ†åŒºidæ’åºï¼Œç„¶åå†™å…¥å•ä¸ªmapè¾“å‡ºæ–‡ä»¶ï¼ŒReducerè¯»å–è‡ªå·±çš„ä¸€ä¸ªè¿ç»­ç‰‡æ®µã€‚å½“è¾“å‡ºæ–‡ä»¶å¤ªå¤§æ—¶ï¼Œä¼šspillåˆ°ç£ç›˜æ–‡ä»¶ï¼Œè¿™äº›ç£ç›˜æ–‡ä»¶æœ€ç»ˆåˆå¹¶è¾“å‡ºä¸€ä¸ªè¾“å‡ºæ–‡ä»¶ã€‚

ä¸¤ç§å†™map è¾“å‡ºæ–‡ä»¶çš„æ–¹å¼ï¼š

1.  åºåˆ—åŒ–æ’åº(é’¨ä¸è®¡åˆ’)ï¼šç¬¦åˆä»¥ä¸‹ä¸‰ä¸ªæ¡ä»¶ï¼š

   - Shuffle ä¾èµ–æ²¡æœ‰æŒ‡å®šèšåˆæˆ–è€…æ’åº
   - shuffleåºåˆ—åŒ–å™¨æ”¯æŒåºåˆ—åŒ–å€¼çš„é‡æ–°å®šä½(ç›®å‰ç”±KryoSerializerå’ŒSpark SQLçš„è‡ªå®šä¹‰åºåˆ—åŒ–å™¨æ”¯æŒ)ã€‚
   - shuffleäº§ç”Ÿçš„è¾“å‡ºåˆ†åŒºå°‘äº16777216ã€‚
2.  éåºåˆ—åŒ–æ’åº:ç”¨äºå¤„ç†æ‰€æœ‰å…¶ä»–æƒ…å†µã€‚

åºåˆ—åŒ–æ’åºæ¨¡å¼ä¸‹ï¼Œä¼ å…¥çš„è®°å½•åœ¨ä¼ é€’ç»™shuffle writeræ—¶å°±è¢«åºåˆ—åŒ–ï¼Œå¹¶ä¸”åœ¨æ’åºè¿‡ç¨‹ä¸­ä»¥åºåˆ—åŒ–çš„å½¢å¼ç¼“å†²ã€‚å®ç°äº†ä¸€äº›ä¼˜åŒ–ï¼š

- å®ƒçš„æ’åºä½œç”¨äºåºåˆ—åŒ–çš„äºŒè¿›åˆ¶æ•°æ®è€Œä¸æ˜¯Javaå¯¹è±¡ï¼Œè¿™å‡å°‘äº†å†…å­˜æ¶ˆè€—å’ŒGCå¼€é”€ã€‚è¿™ç§ä¼˜åŒ–è¦æ±‚è®°å½•åºåˆ—åŒ–ç¨‹åºå…·æœ‰ä¸€å®šçš„å±æ€§ï¼Œå…è®¸åºåˆ—åŒ–è®°å½•åœ¨ä¸éœ€è¦ååºåˆ—åŒ–çš„æƒ…å†µä¸‹é‡æ–°æ’åº
- å®ƒä½¿ç”¨ä¸€ç§ç‰¹æ®Šçš„ç¼“å­˜é«˜æ•ˆæ’åºå™¨([[ShuffleExternalSorter]])ï¼Œå®ƒå¯ä»¥å¯¹å‹ç¼©çš„è®°å½•æŒ‡é’ˆå’Œåˆ†åŒºidè¿›è¡Œæ’åºã€‚é€šè¿‡åœ¨æ’åºæ•°ç»„ä¸­åªä½¿ç”¨8ä¸ªå­—èŠ‚çš„ç©ºé—´ï¼Œè¿™æ›´é€‚åˆäºæ•°ç»„çš„ç¼“å­˜
- spillåˆå¹¶è¿‡ç¨‹è¿è¡Œåœ¨å±äºåŒä¸€åˆ†åŒºçš„åºåˆ—åŒ–è®°å½•å—ä¸Šï¼Œåœ¨åˆå¹¶è¿‡ç¨‹ä¸­ä¸éœ€è¦å¯¹è®°å½•è¿›è¡Œååºåˆ—åŒ–ã€‚
- é«˜æ ¡æ•°æ®å¤åˆ¶ï¼šå½“spillå‹ç¼©codecæ”¯æŒå‹ç¼©æ•°æ®çš„è¿æ¥æ—¶ï¼Œspillåˆå¹¶ç®€å•åœ°è¿æ¥åºåˆ—åŒ–å’Œå‹ç¼©çš„æº¢å‡ºåˆ†åŒºï¼Œä»¥äº§ç”Ÿæœ€ç»ˆçš„è¾“å‡ºåˆ†åŒº

## shuffle write

### bypassæœºåˆ¶

å½“reducerä¸ªæ•°å¾ˆå°æ—¶ï¼Œhashåˆ°å¤šä¸ªæ–‡ä»¶æ˜¯æ¯”sortingåˆ°ä¸€ä¸ªæ–‡ä»¶å¿«çš„ï¼Œå› æ­¤ï¼Œsort shuffleæœ‰ä¸€ä¸ªå›é€€è®¡åˆ’ï¼šå½“reducerä¸ªæ•°å°äºspark.shuffle.sort.bypassMergeThreshold(é»˜è®¤200)ä¸ªæ—¶ï¼Œå¯ç”¨å›é€€è®¡åˆ’ï¼Œhashåˆ°å¤šä¸ªæ–‡ä»¶ç„¶åå†joinåˆ°ä¸€ä¸ªæ–‡ä»¶ã€‚è¯¥å®ç°çš„æºç å‚è€ƒBypassMergeSortShuffleWriterç±»ã€‚

<font color=red>å¦‚æœmapç«¯æ²¡æœ‰èšåˆä¸æ’åºï¼Œä¸”æƒ³å¯ç”¨hash shuffleï¼Œå¯ä»¥è°ƒå¤§spark.shuffle.sort.bypassMergeThreshold</font>

Hash-style shuffle:  æ¯ä¸ªreducerä¸€ä¸ªæ–‡ä»¶ï¼Œå†™å®Œåå†æ‹¼æ¥æˆä¸€ä¸ªè¾“å‡ºæ–‡ä»¶

>  SPARK-6026è®¡åˆ’åˆ é™¤è¿™ä¸ªä»£ç è·¯å¾„

### æ˜¯å¦å¯ç”¨Bypassæœºåˆ¶ï¼Ÿ

```scala
private[spark] object SortShuffleWriter {
  def shouldBypassMergeSort(conf: SparkConf, dep: ShuffleDependency[_, _, _]): Boolean = {
    // We cannot bypass sorting if we need to do map-side aggregation.
    if (dep.mapSideCombine) {
      require(dep.aggregator.isDefined, "Map-side combine without Aggregator specified!")
      false
    } else {
      val bypassMergeThreshold: Int = conf.getInt("spark.shuffle.sort.bypassMergeThreshold", 200)
      dep.partitioner.numPartitions <= bypassMergeThreshold
    }
  }
}
```

![image-20210815222029237](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210815222029237.png)

### æ˜¯å¦å¯ç”¨é’¨ä¸è®¡åˆ’ï¼Ÿ

```scala
 def canUseSerializedShuffle(dependency: ShuffleDependency[_, _, _]): Boolean = {
    val shufId = dependency.shuffleId
    val numPartitions = dependency.partitioner.numPartitions
    if (!dependency.serializer.supportsRelocationOfSerializedObjects) {
      //1. åºåˆ—åŒ–å™¨ä¸æ”¯æŒåºåˆ—åŒ–å¯¹è±¡é‡å®šå‘ï¼ˆé‡æ’åºåˆ—åŒ–å­—èŠ‚ç­‰ä»·äºåºåˆ—åŒ–å‰é‡æ’åºï¼‰
      log.debug(s"Can't use serialized shuffle for shuffle $shufId because the serializer, " +
        s"${dependency.serializer.getClass.getName}, does not support object relocation")
      false
    } else if (dependency.aggregator.isDefined) {
      //2. æ²¡å®šä¹‰èšåˆç®—å­
      log.debug(
        s"Can't use serialized shuffle for shuffle $shufId because an aggregator is defined")
      false
    } else if (numPartitions > MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE) {
      //3. è¾“å‡ºåˆ†åŒºæ•°è¶…è¿‡1600ä¸‡
      log.debug(s"Can't use serialized shuffle for shuffle $shufId because it has more than " +
        s"$MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE partitions")
      false
    } else {
      log.debug(s"Can use serialized shuffle for shuffle $shufId")
      true
    }
```



### Shuffleå¤„ç†å™¨é€‰æ‹©é€»è¾‘

è¿™ä¸ªé€»è¾‘ä¼šç”¨åˆ°ä¸Šé¢Bypassæœºåˆ¶çš„å¯ç”¨ä»¥åŠé’¨ä¸è®¡åˆ’çš„å¯ç”¨

```scala
 override def registerShuffle[K, V, C](
      shuffleId: Int,
      numMaps: Int,
      dependency: ShuffleDependency[K, V, C]): ShuffleHandle = {
    if (SortShuffleWriter.shouldBypassMergeSort(conf, dependency)) {
      /** å¦‚æœæœ‰å°‘äº spark.shuffle.sort.bypassMergeThresholdåˆ†åŒºæ•°ï¼Œæˆ‘ä»¬ä¸éœ€è¦mapç«¯çš„èšåˆï¼Œç„¶åç›´æ¥ç¼–å†™numPartitionsæ–‡ä»¶ï¼Œ
        * å¹¶åœ¨æœ€åå°†å®ƒä»¬è¿æ¥èµ·æ¥ã€‚è¿™é¿å…äº†åºåˆ—åŒ–å’Œååºåˆ—åŒ–ä¸¤æ¬¡ï¼Œä»¥åˆå¹¶æº¢å‡ºçš„æ–‡ä»¶
        * ç¼ºç‚¹æ˜¯åœ¨ä¸€ä¸ªæ—¶é—´å†…æ‰“å¼€å¤šä¸ªæ–‡ä»¶ï¼Œä»è€Œåˆ†é…æ›´å¤šçš„å†…å­˜åˆ°ç¼“å†²åŒºã€‚
        * */
      new BypassMergeSortShuffleHandle[K, V](
        shuffleId, numMaps, dependency.asInstanceOf[ShuffleDependency[K, V, V]])
    } else if (SortShuffleManager.canUseSerializedShuffle(dependency)) {
      // Otherwise, try to buffer map outputs in a serialized form, since this is more efficient: UnsafeShuffleWriter
      //  
      new SerializedShuffleHandle[K, V](
        shuffleId, numMaps, dependency.asInstanceOf[ShuffleDependency[K, V, V]])
    } else {
      // Otherwise, buffer map outputs in a deserialized form:
      // å¦åˆ™ï¼Œç¼“å†²æ˜ å°„è¾“å‡ºä»¥ååºåˆ—åŒ–å½¢å¼è¾“å‡º: å…¶å®å°±ä¼šä½¿ç”¨åŸºç¡€SortShuffleWriter
      new BaseShuffleHandle(shuffleId, numMaps, dependency)
    }
  }
```

![image-20210815232712184](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210815232712184.png)

### è·å–writer

è¿™é‡Œå°±å¾ˆç®€å•äº†ï¼Œæ ¹æ®ä¸åŒçš„shuffleå¤„ç†å™¨åˆ›å»ºä¸åŒçš„writerï¼š

```scala
override def getWriter[K, V](
      handle: ShuffleHandle,
      mapId: Int,
      context: TaskContext): ShuffleWriter[K, V] = {
    numMapsForShuffle.putIfAbsent(
      handle.shuffleId, handle.asInstanceOf[BaseShuffleHandle[_, _, _]].numMaps)
    val env = SparkEnv.get
    handle match {
      case unsafeShuffleHandle: SerializedShuffleHandle[K @unchecked, V @unchecked] =>
        new UnsafeShuffleWriter(
          env.blockManager,
          shuffleBlockResolver.asInstanceOf[IndexShuffleBlockResolver],
          context.taskMemoryManager(),
          unsafeShuffleHandle,
          mapId,
          context,
          env.conf)
      case bypassMergeSortHandle: BypassMergeSortShuffleHandle[K @unchecked, V @unchecked] =>
        new BypassMergeSortShuffleWriter(
          env.blockManager,
          shuffleBlockResolver.asInstanceOf[IndexShuffleBlockResolver],
          bypassMergeSortHandle,
          mapId,
          context,
          env.conf)
      case other: BaseShuffleHandle[K @unchecked, V @unchecked, _] =>
        new SortShuffleWriter(shuffleBlockResolver, other, mapId, context)
    }
```

### MapOutputTracker

MapOutputTrackeræ˜¯ SparkEnvåˆå§‹åŒ–æ˜¯åˆå§‹åŒ–çš„é‡è¦ç»„ä»¶ä¹‹ä¸€  æ˜¯master-slaveçš„ç»“æ„
ç”¨æ¥è·Ÿè¸ªè®°å½•shuffleMapTaskçš„è¾“å‡ºä½ç½® ï¼ˆshuffleMapTaskè¦å†™åˆ°å“ªé‡Œå»ï¼‰ï¼Œ
shuffleReaderè¯»å–shuffleæ–‡ä»¶ä¹‹å‰å°±æ˜¯å»è¯·æ±‚MapOutputTrackerMaster è¦è‡ªå·±å¤„ç†çš„æ•°æ® åœ¨å“ªé‡Œï¼Ÿ
MapOutputTrackerç»™å®ƒè¿”å›ä¸€æ‰¹ MapOutputTrackerWorkerçš„åˆ—è¡¨ï¼ˆåœ°å€ï¼Œportç­‰ä¿¡æ¯ï¼‰
shuffleReaderå¼€å§‹è¯»å–æ–‡ä»¶  è¿›è¡ŒåæœŸå¤„ç†

æ•°æ®ç»“æ„

![image-20210827153403865](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210827153403865.png)

```scala


  /** åœ¨map outçš„é›†åˆmapStatusesä¸­æ³¨å†Œæ–°çš„Shuffleï¼Œå‚æ•°ä¸ºShuffle idå’Œmapçš„ä¸ªæ•°ã€‚  */
  def registerShuffle(shuffleId: Int, numMaps: Int) {
    if (mapStatuses.put(shuffleId, new Array[MapStatus](numMaps)).isDefined) {
      throw new IllegalArgumentException("Shuffle ID " + shuffleId + " registered twice")
    }
    // add in advance
    shuffleIdLocks.putIfAbsent(shuffleId, new Object())
  }

  /** æ ¹æ®Shuffle idåœ¨mapStatusesä¸­ä¸ºShuffleæ·»åŠ map outçš„çŠ¶æ€ï¼ˆå­˜å‚¨çš„map outå…¶å®å°±æ˜¯map outçš„çŠ¶æ€ï¼‰ã€‚ */
  def registerMapOutput(shuffleId: Int, mapId: Int, status: MapStatus) {
    val array = mapStatuses(shuffleId)
    array.synchronized {
      array(mapId) = status
    }
  }
```



![image-20210827151326184](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210827151326184.png)



æ³¨å†Œè°ƒç”¨é“¾ï¼š

![image-20210827152340387](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210827152340387.png)

æ³¨å†Œæ–°çš„shuffle

```scala
    if (mapOutputTracker.containsShuffle(shuffleDep.shuffleId)) {
      // A previously run stage generated partitions for this shuffle, so for each output
      // that's still available, copy information about that output location to the new stage
      // (so we don't unnecessarily re-compute that data).
      // å¦‚æœå½“å‰shuffleå·²ç»åœ¨MapOutputTrackerä¸­æ³¨å†Œè¿‡
      val serLocs = mapOutputTracker.getSerializedMapOutputStatuses(shuffleDep.shuffleId)
      val locs = MapOutputTracker.deserializeMapStatuses(serLocs)
      // æ›´æ–°Shuffleçš„Shuffle Writeè·¯å¾„
      (0 until locs.length).foreach { i =>
        if (locs(i) ne null) {
          // locs(i) will be null if missing
          stage.addOutputLoc(i, locs(i))
        }
      }
    } else {
      // å¦‚æœå½“å‰Shuffleæ²¡æœ‰åœ¨MapOutputTrackerä¸­æ³¨å†Œè¿‡
      // Kind of ugly: need to register RDDs with the cache and map output tracker here
      // since we can't do it in the RDD constructor because # of partitions is unknown
      logInfo("Registering RDD " + rdd.id + " (" + rdd.getCreationSite + ")")
      // æ³¨å†Œ
      mapOutputTracker.registerShuffle(shuffleDep.shuffleId, rdd.partitions.length)
    }
```



### Shuffle Mapè¿‡ç¨‹

#### mapTaskæŒ‰ä»€ä¹ˆè§„åˆ™è¿›è¡Œoutput?

```scala
private[spark] class ShuffleMapTask(
    stageId: Int,
    taskBinary: Broadcast[Array[Byte]],
    partition: Partition,
    @transient private var locs: Seq[TaskLocation])
  extends Task[MapStatus](stageId, partition.index) with Logging {
    
  override def runTask(context: TaskContext): MapStatus = {
    val ser = SparkEnv.get.closureSerializer.newInstance()
    val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])](
      ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)

    metrics = Some(context.taskMetrics)
    var writer: ShuffleWriter[Any, Any] = null
    try {
      val manager = SparkEnv.get.shuffleManager
      writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context)
      writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ <: Product2[Any, Any]]])
      return writer.stop(success = true).get
    } catch {
      case e: Exception =>
        try {
          if (writer != null) {
            writer.stop(success = false)
          }
        } catch {
          case e: Exception =>log.debug("Could not stop writer", e)
        }
        throw e
    }
  }
}
```

æ ¸å¿ƒå°±æ˜¯ShuffleMapTask.runTaskçš„å®ç°, æ¯ä¸ªè¿è¡Œåœ¨Executorä¸Šçš„Task, é€šè¿‡SparkEnvè·å–shuffleManagerå¯¹è±¡, ç„¶åè°ƒç”¨getWriteræ¥å½“å‰MapID=partitionIdçš„ä¸€ç»„Writer.
ç„¶åå°†rddçš„è¿­ä»£å™¨ä¼ é€’ç»™writer.writeå‡½æ•°, ç”±æ¯ä¸ªWriterçš„å®ç°å»å®ç°å…·ä½“çš„writeæ“ä½œ;

#### reduceTaskæŒ‰ä»€ä¹ˆè§„åˆ™è¿›è¡Œreduce?

ShuffleBlockManager, å’ŒSparkå†…éƒ¨çš„BlockManagerç›¸ä¼¼, åªæ˜¯æŠŠShuffleçš„write/reduceéƒ½æŠ½è±¡ä¸ºblockçš„æ“ä½œ, å¹¶ç”±ShuffleBlockManagerè¿›è¡ŒBlockç®¡ç†;

## Shuffle Read

> ä¸Šé¢æˆ‘ä»¬è°ˆåˆ°äº†ShuffleMapStage,å…¶å®æ˜¯Shuffle Mapçš„è¿‡ç¨‹,å³ShuffleMapStageçš„ShuffleMapTaskæŒ‰ç…§ä¸€å®šçš„è§„åˆ™å°†æ•°æ®å†™åˆ°ç›¸åº”çš„æ–‡ä»¶ä¸­,å¹¶æŠŠå†™çš„æ–‡ä»¶"ä½ç½®ä¿¡æ¯"
> ä»¥MapStatusè¿”å›ç»™DAGScheduler ,MapStatuså°†å®ƒæ›´æ–°åˆ°ç‰¹å®šä½ç½®å°±å®Œæˆäº†æ•´ä¸ªShuffle Mapè¿‡ç¨‹.  
> åœ¨Sparkä¸­,Shuffle reduceè¿‡ç¨‹æŠ½è±¡åŒ–ä¸ºShuffledRDD,å³è¿™ä¸ªRDDçš„computeæ–¹æ³•è®¡ç®—æ¯ä¸€ä¸ªåˆ†ç‰‡å³æ¯ä¸€ä¸ªreduceçš„æ•°æ®æ˜¯é€šè¿‡æ‹‰å–ShuffleMapè¾“å‡ºçš„æ–‡ä»¶å¹¶è¿”å›Iteratoræ¥å®ç°çš„

å¯¹äºæ¯ä¸ªstageæ¥è¯´ï¼Œå®ƒçš„ä¸Šè¾¹ç•Œï¼Œè¦ä¹ˆä»å¤–éƒ¨å­˜å‚¨è¯»å–æ•°æ®ï¼Œè¦ä¹ˆè¯»å–ä¸Šä¸€ä¸ªstageçš„è¾“å‡ºã€‚è€Œä¸‹è¾¹ç•Œè¦ä¹ˆæ˜¯é€šè¿‡ShuffleMapTaskå†™å…¥åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼Œè¦ä¹ˆå°±æ˜¯æœ€åä¸€ä¸ªstage,å†™å‡ºç»“æœæ–‡ä»¶ã€‚è¿™é‡Œçš„stageåœ¨è¿è¡Œæ—¶å°±å¯ä»¥ä»¥æµæ°´çº¿çš„æ–¹å¼è¿›è¡Œè¿è¡Œä¸€ç»„Taskï¼Œé™¤äº†æœ€åä¸€ä¸ªstageå¯¹åº”çš„ResultTaskï¼Œå…¶ä½™çš„stageå…¨éƒ¨å¯¹åº”çš„shuffle Map Taskã€‚

ã€€ã€€é™¤äº†éœ€è¦ä»å¤–éƒ¨å­˜å‚¨è¯»å–æ•°æ®å’ŒRDDå·²ç»åšè¿‡cacheæˆ–è€…checkPointçš„Taskã€‚ä¸€èˆ¬çš„Taskéƒ½æ˜¯ä»Shuffle RDDçš„ShuffleReadå¼€å§‹çš„

### ShuffledRDD

,Shuffleè¿‡ç¨‹æ˜¯åŒ…æ‹¬Mapå’ŒReduceä¸¤ä¸ªè¿‡ç¨‹;å…¶ä¸­Shuffle Mapä»¥ShuffleMapStageçš„å½¢å¼å­˜åœ¨, Shuffle Reduceè¢«æŠ½è±¡ä¸ºä¸€ä¸ªRDD,è¯¥RDDçš„computeå‡½æ•°æœ‰ç‚¹ç‰¹æ®Šè€Œå·²

### è·å–Shuffleé˜…è¯»å™¨

ShuffledRDD:  å¯¹æ¥çš„æ˜¯ShuffleManagerï¼Œä½†å½“å‰åªæœ‰SortShuffleManageräº† ğŸ˜¢

```scala
  override def compute(split: Partition, context: TaskContext): Iterator[(K, C)] = {
    val dep = dependencies.head.asInstanceOf[ShuffleDependency[K, V, C]]
    SparkEnv.get.shuffleManager.getReader(dep.shuffleHandle, split.index, split.index + 1, context)
      .read()
      .asInstanceOf[Iterator[(K, C)]]
  }
```

SortShuffleManager: çœŸæ­£è´Ÿè´£åˆ›å»ºé˜…è¯»å™¨

```scala
  override def getReader[K, C](
      handle: ShuffleHandle,
      startPartition: Int,
      endPartition: Int,
      context: TaskContext): ShuffleReader[K, C] = {
    new BlockStoreShuffleReader(
      handle.asInstanceOf[BaseShuffleHandle[K, _, C]], startPartition, endPartition, context)
  }
```



### readå®ç°

å¤§ä½“é€»è¾‘ï¼š

1. åˆ›å»ºæ•°æ®å—è¯»å–æµï¼Œ æµçš„å‚æ•°å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†æ€§èƒ½ï¼
2. è·å–åºåˆ—åŒ–å™¨
3. ååºåˆ—åŒ–è¯»å–æµï¼Œå¹¶è½¬ä¸ºKeyValue
4. å¦‚æœå®šä¹‰äº†èšåˆå™¨ï¼Œåˆ™è¿›è¡Œèšåˆ
5. å¦‚æœå®šä¹‰äº†æ’åºï¼Œåˆ™ä½¿ç”¨ExternalSorterè¿›è¡Œæ’åº

```scala
override def read(): Iterator[Product2[K, C]] = {
    val wrappedStreams = new ShuffleBlockFetcherIterator(
      context,
      blockManager.shuffleClient,
      blockManager,
      mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition),
      serializerManager.wrapStream,
      SparkEnv.get.conf.getSizeAsMb("spark.reducer.maxSizeInFlight", "48m") * 1024 * 1024,
      SparkEnv.get.conf.getInt("spark.reducer.maxReqsInFlight", Int.MaxValue),
      SparkEnv.get.conf.get(config.REDUCER_MAX_REQ_SIZE_SHUFFLE_TO_MEM),
      SparkEnv.get.conf.getBoolean("spark.shuffle.detectCorrupt", true))

    val serializerInstance = dep.serializer.newInstance()

    // Create a key/value iterator for each stream
    val recordIter = wrappedStreams.flatMap { case (blockId, wrappedStream) =>
      serializerInstance.deserializeStream(wrappedStream).asKeyValueIterator
    }

    // Update the context task metrics for each record read.
    val readMetrics = context.taskMetrics.createTempShuffleReadMetrics()
    val metricIter = CompletionIterator[(Any, Any), Iterator[(Any, Any)]](
      recordIter.map { record =>
        readMetrics.incRecordsRead(1)
        record
      },
      context.taskMetrics().mergeShuffleReadMetrics())

    // An interruptible iterator must be used here in order to support task cancellation
    val interruptibleIter = new InterruptibleIterator[(Any, Any)](context, metricIter)

    val aggregatedIter: Iterator[Product2[K, C]] = if (dep.aggregator.isDefined) {
      if (dep.mapSideCombine) {
        // We are reading values that are already combined
        val combinedKeyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, C)]]
        dep.aggregator.get.combineCombinersByKey(combinedKeyValuesIterator, context)
      } else {
        // We don't know the value type, but also don't care -- the dependency *should*
        // have made sure its compatible w/ this aggregator, which will convert the value
        // type to the combined type C
        val keyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, Nothing)]]
        dep.aggregator.get.combineValuesByKey(keyValuesIterator, context)
      }
    } else {
      require(!dep.mapSideCombine, "Map-side combine without Aggregator specified!")
      interruptibleIter.asInstanceOf[Iterator[Product2[K, C]]]
    }

    // Sort the output if there is a sort ordering defined. æ’åº
    dep.keyOrdering match {
      case Some(keyOrd: Ordering[K]) =>
        // Create an ExternalSorter to sort the data.
        val sorter =
          new ExternalSorter[K, C, C](context, ordering = Some(keyOrd), serializer = dep.serializer)
        sorter.insertAll(aggregatedIter)
        context.taskMetrics().incMemoryBytesSpilled(sorter.memoryBytesSpilled)
        context.taskMetrics().incDiskBytesSpilled(sorter.diskBytesSpilled)
        context.taskMetrics().incPeakExecutionMemory(sorter.peakMemoryUsedBytes)
        CompletionIterator[Product2[K, C], Iterator[Product2[K, C]]](sorter.iterator, sorter.stop())
      case None =>
        aggregatedIter
    }
  }
```

æµçš„å‚æ•°å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†æ€§èƒ½ï¼å›å¤´çœ‹åˆ›å»ºæµçš„å››ä¸ªå‚æ•°ï¼š

maxBytesInFlight åŒæ—¶è¯»å–è¿œç¨‹å—çš„æœ€å¤§å¤§å°ï¼Œé»˜è®¤48m
maxReqsInFlight åŒæ—¶è¯»å–è¿œç¨‹å—çš„æœ€å¤§è¯·æ±‚æ•°, é»˜è®¤Int.Max
maxReqSizeShuffleToMem ä¸€ä¸ªè¯·æ±‚æœ€å¤§èƒ½ç¼“å­˜çš„å¤§å°ï¼Œé€šè¿‡spark.reducer.maxReqSizeShuffleToMemé…ç½®ï¼Œé»˜è®¤Long.Max
detectCorrupt æ˜¯å¦æ£€æµ‹è¯»å–å´©æºƒï¼Œé»˜è®¤true



ä¼˜åŒ–:
é»˜è®¤å€¼ï¼š48må‚æ•°è¯´æ˜ï¼šå†³å®šäº†æ¯æ¬¡èƒ½å¤Ÿæ‹‰å–å¤šå°‘æ•°æ®ã€‚

> æ³¨æ„ï¼Œè¿™é‡Œç½‘ä¸Šå¾ˆå¤šéƒ½è¯´é”™äº†ï¼Œä»–è·Ÿç¼“å­˜ä¸æ˜¯ä¸€ä¸ªäº‹æƒ…å•Š

è°ƒä¼˜å»ºè®®ï¼šå¦‚æœä½œä¸šå¯ç”¨çš„å†…å­˜èµ„æºè¾ƒä¸ºå……è¶³çš„è¯ï¼Œå¯ä»¥é€‚å½“å¢åŠ è¿™ä¸ªå‚æ•°çš„å¤§å°ï¼ˆæ¯”å¦‚96mï¼‰ï¼Œä»è€Œå‡å°‘æ‹‰å–æ•°æ®çš„æ¬¡æ•°ï¼Œä¹Ÿå°±å¯ä»¥å‡å°‘
ç½‘ç»œä¼ è¾“çš„æ¬¡æ•°ï¼Œè¿›è€Œæå‡æ€§èƒ½ã€‚åœ¨å®è·µä¸­å‘ç°ï¼Œåˆç†è°ƒèŠ‚è¯¥å‚æ•°ï¼Œæ€§èƒ½ä¼šæœ‰1%~5%çš„æå‡ã€‚

é”™è¯¯ï¼šreduce oom
reduce taskå»mapæ‹‰æ•°æ®ï¼Œreduce ä¸€è¾¹æ‹‰æ•°æ®ä¸€è¾¹èšåˆ   reduceæ®µæœ‰ä¸€å—èšåˆå†…å­˜ï¼ˆexecutor memory * 0.2ï¼‰
è§£å†³åŠæ³•ï¼š
1ã€å¢åŠ reduce èšåˆçš„å†…å­˜çš„æ¯”ä¾‹  è®¾ç½®spark.shuffle.memoryFraction
2ã€ å¢åŠ executor memoryçš„å¤§å°  --executor-memory 5G
3ã€å‡å°‘reduce taskæ¯æ¬¡æ‹‰å–çš„æ•°æ®é‡  è®¾ç½®spark.reducer.maxSizeInFlight  24m





[spark shuffleæ–‡ä»¶å¯»å€æµç¨‹](https://mp.weixin.qq.com/s?__biz=MzIwMjA2MTk4Ng==&mid=2247485116&idx=1&sn=82bd42f76836e67206d317135aa0c89c&chksm=96e52771a192ae6784d3f21fef53ed0c2b43e1caeefea94cc6f8f6725f883b3b7d6c65cf6ffb&scene=21#wechat_redirect)

**MapOutPutTrackerï¼š**MapOutPutTracker æ˜¯ spark é‡Œé¢çš„ä¸€ä¸ªæ¨¡å—ï¼Œä¸»ä»æ¶æ„ï¼Œç”¨æ¥ç®¡ç†ç£ç›˜å°æ–‡ä»¶çš„åœ°å€ã€‚

MapOutPutTrackerMaster æ˜¯ä¸»ï¼Œå­˜åœ¨äº Driver ä¸­ï¼›

MapOutPutTrackerWorker æ˜¯ä»ï¼Œå­˜åœ¨äº Executor ä¸­ï¼›

**BlockManagerï¼š**å—ç®¡ç†è€…ï¼Œä¹Ÿæ˜¯ä¸€ä¸ª spark ä¸­çš„ä¸€ä¸ªæ¨¡å—ï¼Œä¸»ä»æ¶æ„ã€‚

BlockManagerMaster æ˜¯ä¸»ï¼Œå­˜åœ¨äº Driver ä¸­ã€‚ç”¨äºåœ¨é›†ç¾¤ä¸­ä¼ é€’å¹¿æ’­å˜é‡æˆ–ç¼“å­˜æ•°æ®æˆ–åˆ é™¤æ•°æ®çš„æ—¶å€™é€šçŸ¥å…¶ä»–çš„ è·ŸéšèŠ‚ç‚¹æ¥è¿›è¡Œç›¸åº”çš„æ“ä½œã€‚è¯´ç™½äº†å°±æ˜¯æŒ‡æŒ¥ã€‚

BlockManagerWorkeræ˜¯ä»ï¼Œå­˜åœ¨äº Executor ä¸­ã€‚ä¼šä¸ BlockManagerMasterèŠ‚ç‚¹è¿›è¡Œé€šä¿¡ã€‚

æ— è®ºåœ¨ Driver ç«¯çš„ BlockManager è¿˜æ˜¯åœ¨ Excutor ç«¯çš„BlockManager éƒ½å«æœ‰å››ä¸ªå¯¹è±¡ï¼š

â‘  DiskStore:è´Ÿè´£ç£ç›˜çš„ç®¡ç†ã€‚

â‘¡ MemoryStoreï¼šè´Ÿè´£å†…å­˜çš„ç®¡ç†ã€‚

â‘¢ConnectionManagerè´Ÿè´£è¿æ¥å…¶ä»–BlockManagerWorkerã€‚

â‘£ BlockTransferService:è´Ÿè´£æ•°æ®çš„ä¼ è¾“ã€‚



![image-20210903164055570](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/image-20210903164055570.png)

1. map taskè¿è¡Œå®Œæ¯•ä¹‹åï¼Œä¼šå°† task æ‰§è¡Œä¹‹åçš„äº§ç”Ÿçš„ç£ç›˜å°æ–‡ä»¶çš„åœ°å€å°è£…åˆ° MapStatus å¯¹è±¡ä¸­ã€‚é€šè¿‡ MapOutpuTrackerWorkerå¯¹è±¡å‘ Driver ä¸­çš„ MapOutputTrackerMaster æ±‡æŠ¥ã€‚

2. åœ¨æ‰€æœ‰çš„ map task æ‰§è¡Œå®Œæ¯•åï¼ŒDriver ä¸­å°±æŒæ¡äº†æ‰€æœ‰çš„ç£ç›˜å°æ–‡ä»¶çš„åœ°å€ã€‚

3. åœ¨ reduce task æ‰§è¡Œä¹‹å‰ï¼Œä¼šé€šè¿‡Executor ä¸­MapOutPutTrackerWorker å‘ Driver ç«¯çš„ MapOutputTrackerMaster è·å–ç£ç›˜å°æ–‡ä»¶çš„åœ°å€ã€‚

4. è·å–åˆ°ç£ç›˜å°æ–‡ä»¶çš„åœ°å€åï¼Œä¼šé€šè¿‡ BlockManager ä¸­çš„ ConnectionManager è¿æ¥æ•°æ®æ‰€åœ¨èŠ‚ç‚¹ä¸Šçš„ ConnectionManager, ç„¶åé€šè¿‡ BlockTransferService è¿›è¡Œæ•°æ®çš„ä¼ è¾“ã€‚

5. BlockTransferService é»˜è®¤å¯åŠ¨ 5 ä¸ª task å»èŠ‚ç‚¹æ‹‰å–æ•°æ®ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ5 ä¸ª task æ‹‰å–æ•°æ®é‡ä¸èƒ½è¶…è¿‡ 48 Mã€‚æ‹‰å–è¿‡æ¥çš„æ•°æ®æ”¾åœ¨ Executorç«¯çš„shuffleèšåˆå†…å­˜ä¸­ï¼ˆspark.shuffle.memeoryFraction 0.2ï¼‰, å¦‚æœ5 ä¸ª task ä¸€æ¬¡æ‹‰å–çš„æ•°æ®æ”¾ä¸åˆ°shuffleå†…å­˜ä¸­ä¼šæœ‰ OOM,å¦‚æœæ”¾ä¸‹ä¸€æ¬¡ï¼Œä¸ä¼šæœ‰ OOMï¼Œä»¥åæ”¾ä¸ä¸‹çš„ä¼šæ”¾ç£ç›˜ã€‚
