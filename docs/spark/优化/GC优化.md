# [Spark优化](https://blog.csdn.net/ainidong2005/article/details/53141822)

在Spark中GC优化的目标是，只有生命周期足够大的RDD才能够被放到老年代之中，并且保证新生代的空间足够用来存储程序运行期间的短生命周期对象。这将有利于预防对程序运行期创建的临时对象使用Full GC进行空间回收，如下几点将会对此起到帮助：

1）通过收集GC状态信息监控是否发生了过多的GC操作，如果在task未完成之前发生了**多次Full GC**那么读者就需要注意了，这表明没有足够的内存来执行相关task。

2）如果有许多Minor GC但是Major GC并不是很多，这时候给Eden区分配更多的空间是有帮助的。读者可以将Eden的空间设置为每个task执行时需要消耗的内存，或者比此内存大。假设Eden大小被估计为E，那么新生代的大小可以估计为 -Xmn = 4/3 * E(-Xmn设置新生代所占空间大小，顺便提一下JVM中Eden区与Survivor区比例为8:1，因此按照JVM中算法 -Xmn = 5/4 * E（新生代=E+1/8E+1/8E=5/4E）,spark中将Eden区缩小了。比例可以通过JVM SurvivorRatio进行设置)

Minor GC: 发生在新生代的垃圾收集动作，Java大对象大多都是朝生夕灭，故而Minor GC十分频繁

**Major GC: Full GC,发生在老年代的GC，其速度一般会比Minor GC慢十倍左右，并且是Stop-the-World**

3）**如果监控到老年代空间将满，那么便需要减小用作cache的空间大小，通过设置spark.memory.fraction即可**。spark.memory.fraction（默认值为0.75）：用于设置存储内存和执行内存占用堆内存的比例。若值越低，则发生spill和evict的频率就越高。相比于降低任务的执行效率，缓存少量的数据是可取的。另外，可以考虑减少新生代的空间大小，也就是通过-Xmn即可实现。如果没有设置-Xmn属性的话，也可以通过设置JVM的NewRatio参数来实现，**JVM虚拟机默认该值为2，这表示老年代占据堆区的2/3**，该参数的取值应该足够大，至少要超过spark.memory.fraction的值。这样就表示**老年代的空间足够用来保存存储内存中的对象**(也就是说整个堆的75%，差不多2/3用做spark的统一内存，也是JVM默认的老年代比例)。

4）尝试用用G1垃圾回收器。启用方式为：


 -XX:+UseG1GC
此垃圾回收器能够在某些回收成为瓶颈的项目中显著提升性能，有一点需要注意，如果executor节点的堆区很大，那么增加G1的独立区域（Region）是有必要的，这个值可以通过   -XX:G1HeapRegionSize 进行设置。
G1独立区域（Region）使用G1收集器时，JAVA堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离，它们都是一份Region（不需要联系）的集合。

5）假如你的程序正在执行从HDFS中读取数据的任务，那么该任务的内存消耗则可以通过HDFS中数据块的大小进行推断。需要注意的是解压后的数据块常常为原始数据块的2或3倍。因此假如我们想要拥有3-4个工作空间的内存，并且HDFS中blockSize为64M，那么可以估计出Eden区域大约需要

E = 4 * 3 * 64MB , -Xmn = 4/3 * E ==>  -Xmn = 1024M

6）对参数进行设置之后，监控垃圾回收的频率与消耗时间，对比查看是否有效。

Spark Executor会将JVM的heap空间大体分为两个部分，一部分用来存放Spark应用中持久化到内存中的RDD数据，剩下的部分则用来做为JVM运行时的堆空间，负责RDD转化等过程当中的内存消耗。咱们能够经过spark.storage.memoryFraction参数调节这两块内存的比例