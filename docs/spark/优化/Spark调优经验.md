# 小文件问题

## 问题

数据按天分区，spark入库任务是16个并行度，10分钟一个批次，一天将产生24x6x16=2304个小文件，给NameNode带来压力。

## 解决方案

每晚凌晨合并前一天的数据，读取所有数据，写入到一个文件中，然后覆盖之前的所有小文件。

### 问题：

 合并程序本身效率低，且有一天的延迟

### 优化

合并写入变为并行写入，通过修改目录名称实现数据替换，去掉了回写步骤

使用coalesce代替repartition，这俩函数用于改变分区数，但coalesce跨分区移动的数据会比repartition少。

## 小表

[小表join大表](https://www.cnblogs.com/wwcom123/p/10586607.html)

