二、作业参数

1、动态分配

```scala
1 spark.dynamicAllocation.enabled // 开启动态资源分配
2 spark.dynamicAllocation.initialExecutors=50 
3 spark.dynamicAllocation.maxExecutors //开启动态资源分配后，最多可分配的Executor数 
4 spark.dynamicAllocation.minExecutors //开启动态资源分配后，最少可分配的Executor数
```



2、并行度

```scala
spark.default.parallelism //只有在处理RDD时有效.
spark.sql.shuffle.partitions //默认200，一般只对SparkSQL有效，一个作业一旦设置了该参数，它运行过程中的所有阶段的reduce个数都是同一个值。可以开下面的自适应
```



3、内存相关

```scala
spark.yarn.executor.directMemoryOverhead=2000
spark.executor.memoryOverhead=2048
```

内存计算公式：directMemoryOverhead=memoryOverhead-jvmOverhead

堆外内存 memoryOverhead 这个作用于YARN，384M~0.1*堆内存

真堆外内存是：spark.memory.offHeap.size，需同步开启spark.memory.offHeap.enabled

4、spark sql 自适应AQE(Adaptive Query Exection)

```scala
spark.sql.adaptive.enabled=false //自适应执行框架的开关 
spark.sql.adaptive.minNumPostShufflePartitions = 1 //reduce个数区间最小值(spark v2.4 有 3.0 已经去掉)
spark.sql.adaptive.maxNumPostShufflePartitions = 500 //reduce个数区间最大值 
spark.sql.adaptive.shuffle.targetPostShuffleInputSize=67108864 //动态调整reduce个数的partition大小依据，如设置64MB则reduce阶段每个task最少处理64MB的数据 
spark.sql.adaptive.shuffle.targetPostShuffleRowCount=20000000 //动态调整reduce个数的partition条数依据，如设置20000000则reduce阶段每个task最少处理20000000条的数据
```



工场alpha默认的是Spark 3.1 ，Spark 3.0以上用以下参数

```scala
--conf spark.sql.adaptive.enabled=true 
--conf spark.sql.adaptive.coalescePartitions.enabled=true //是否合并临近的shuffle分区（根据spark.sql.adaptive.advisoryPartitionSizeInBytes的阈值来合并，默认64M）
--conf spark.sql.adaptive.coalescePartitions.initialPartitionNum=1 //shuffle合并分区之前的初始分区数，默认为spark.sql.shuffle.partitions的值
--conf spark.sql.adaptive.coalescePartitions.parallelismFirst=false //默认true，开启时会忽略advisoryPartitionSizeInBytes设置的大下，转而遵循指定的最小分区大小spark.sql.adaptive.coalescePartitions.minPartitionSize（默认为 1MB），以最大化并行度。
```



 容错机制：

```scala
spark.yarn.maxAppAttempts=yarn.resourcemanager.am.max-attempts=2//当executor/stage/task挂了一定个数之后，整个任务就会挂掉spark.yarn.max.executor.failures
spark.stage.maxConsecutiveAttempts=4
spark.task.maxFailures=4
```



5、数据倾斜

| 属性名称                                            | 默认值   | 备注                                                         |
| --------------------------------------------------- | -------- | ------------------------------------------------------------ |
| spark.sql.adaptive.enabled                          | false    | 自适应执行框架的开关                                         |
| spark.sql.adaptive.skewedJoin.enabled               | false    | 倾斜处理开关                                                 |
| spark.sql.adaptive.skewedPartitionFactor            | 10       | 当一个partition的size大小 大于 该值(所有parititon大小的中位数) 且 大于spark.sql.adaptive.skewedPartitionSizeThreshold，或者parition的条数 大于 该值(所有parititon条数的中位数) 且 大于 spark.sql.adaptive.skewedPartitionRowCountThreshold， 才会被当做倾斜的partition进行相应的处理 |
| spark.sql.adaptive.skewedPartitionSizeThreshold     | 67108864 | 倾斜的partition大小不能小于该值                              |
| spark.sql.adaptive.skewedPartitionRowCountThreshold | 10000000 | 倾斜的partition条数不能小于该值                              |
| spark.shuffle.statistics.verbose                    | false    | 打开后MapStatus会采集每个partition条数的信息，用于倾斜处理   |

6、Runtime执行计划优化

当参与 Join 的一方足够小，可全部置于 Executor 内存中时，可使用 Broadcast 机制将整个 RDD 数据广播到每一个 Executor 中，该 Executor 上运行的所有 Task 皆可直接读取其数据。

与 SortMergeJoin 相比，BroadcastJoin 不需要 Shuffle，减少了 Shuffle 带来的开销，同时也避免了 Shuffle 带来的数据倾斜，从而极大地提升了 Job 执行效率。 同时，BroadcastJoin 带来了广播小 RDD 的开销。另外，如果小 RDD 过大，无法存于 Executor 内存中，则无法使用 BroadcastJoin。

SparkSQL自适应执行框架会在物理执行计划真正运行的过程中，动态的根据shuffle阶段shuffle write的实际数据大小，来调整是否可以用BroadcastJoin来代替SortMergeJoin，提高运行效率。

```scala
spark.sql.adaptive.join.enabled=true
```



spark.sql.adaptiveBroadcastJoinThreshold 等于spark.sql.autoBroadcastJoinThreshold 运行过程中用于判断是否满足BroadcastJoin条件

设置为不推断schema，适用于分区超多导致读取慢、OOM的表（spark3.0以上默认不推断）

```scala
spark.sql.hive.caseSensitiveInferenceMode=NEVER_INFER
```



7. hint

```sql
SELECT /*+ MAPJOIN(table_name) */
 
SELECT /*+ BROADCASTJOIN(table_name) */ 
 
SELECT /*+ BROADCAST(table_name) */ 
 
// spark -2.4.0 之后新增的功能
// 由中国贡献者提出并参与贡献
// https://issues.apache.org/jira/browse/SPARK-24940
 
SELECT /*+ REPARTITION(number) */ 
 
SELECT /*+ COALESCE(number) */ 
 
```

