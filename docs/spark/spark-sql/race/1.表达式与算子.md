# spark-race(一)表达式与算子

>回答：什么是Dpu表达式、算子，以及如何执行

## (一)表达式Expresion

### DpuExpresion

**核心接口**：
def columnarEval*(*batch: ColumnarBatch*)*: Any
**说明**：这是表达式、算子的执行入口
**返回值**： 表达式对整个batch的执行结果，可能是一个DpuColumnVector或者是一个标量值scalar



### DpuUnaryExpression extends UnaryExpression with DpuExpression

**调用逻辑**：columnarEval→doItColumnar->doColumnar
**核心接口：**
def doColumnar*(*input: DpuColumnVector*)*: RaceColumnVector
doItColumnar会调用doColumnar得到RaceCV
def doItColumnar*(*input: DpuColumnVector*)*: DpuColumnVector
调用doColumnar并 把RaceCV转为DpuCV
def columnarEval*(*batch: ColumnarBatch*)*: Any
调用子节点的columnarEval得到DpuCV
子类
DpuAlias: 入口直接调用子类的入口，无需调用doColumnar
下面三个实现了RaceUnaryExpression trait， 会调用JNI的接口，只是传入的UnaryOperator不一样
DpuNot: 计算子节点
DpuISNULL: 计算input
DpuISNOTNULL:  计算input


### DpuBinaryExpression extends BinaryExpression with DpuExpression

**核心接口**：
def doColumnar(lhs: DpuColumnVector, rhs: DpuColumnVector): RaceColumnVector
def doColumnar(lhs: Array[Byte], rhs: DpuColumnVector): RaceColumnVector
def doColumnar(lhs: DpuColumnVector, rhs: Array[Byte]): RaceColumnVector
def doColumnar(numRows: Int, lhs: Array[Byte], rhs: Array[Byte]): RaceColumnVector
入口：
def columnarEval*(*batch: ColumnarBatch*)*: Any

```
= {
    (left.columnarEval(batch), right.columnarEval(batch)) match {
      case (l: DpuColumnVector, r: DpuColumnVector) =>
        DpuColumnVector.convertRaceCVToDpuCV(doColumnar(l, r), dataType)
      case (l: Array[Byte], r: DpuColumnVector) =>
        DpuColumnVector.convertRaceCVToDpuCV(doColumnar(l, r), dataType)
      case (l: DpuColumnVector, r: Array[Byte]) =>
        DpuColumnVector.convertRaceCVToDpuCV(doColumnar(l, r), dataType)
      case (l: Array[Byte], r: Array[Byte]) =>
        DpuColumnVector.convertRaceCVToDpuCV(doColumnar(batch.numRows(), l, r), dataType)
      case (l, r) =>
        throw new UnsupportedOperationException(
          s"Unsupported data '($l: " +
            s"${l.getClass}, $r: ${r.getClass})' for DPU binary expression."
        )
    }
  }
}
```

**对于二元运算，先计算左、右节点，再调用doColumnar计算自己，所以是对算子树的后续递归遍历**。

二元表达式都继承了BinaryOperator特质，而该特质提供了实现二元计算的binaryOperation接口，
另外，实现了RaceBinaryExpression特质的二元表达式，其doColumnar方法都通过binaryOperation调用JNI接口实现。

一元表达式
![image-20230609171724091](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image-20230609171724091.png)

二元表达式
![image-20230609171737916](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image-20230609171737916.png)

## (二)算子 SparkPlan

>原生SparkPlan提供了一个方法executeColumnar获取查询结果，它调用了doExecuteColumnar(), 我们需要实现doExecuteColumnar()

**核心接口：**
def doExecuteColumnar*()*: RDD*[*ColumnarBatch*]*
描述：产出查询结果

算子分为一元算子、二元算子
![image-20230609171801404](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image-20230609171801404.png)

### 一元算子:DpuFilterExec

DpuFilterExec*(
                          *condition: Expression,
                          child: SparkPlan,
                          override val coalesceAfter: Boolean = true
                        *) *extends UnaryExecNode with DpuPredicateHelper with DpuExec
**核心逻辑**：

1. 条件表达式和子节点的输出属性AttributeSeq序列进行绑定
2. 对子节点完成计算后的RDD做map，  利用绑定后的表达式得到过滤后的RDD， 这一步分为几个步骤
    1. 条件表达式树在batch上projectSingle计算得到filterMask（这一步会递归遍历计算表达式树）
    2. 从batch提取schema 构造一个RaceTable
    3. 对RaceTable的每列构造handle参数，利用filterMask调用JNI接口得到过滤结果


例如id=1这个表达式，绑定到这个Filter算子上

id=1也是一个表达式树：
![image-20230609171822215](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image-20230609171822215.png)
DpuAnd: 树根
left: DpuNotNull
right:DpuEqualTo
left: id(DpuBoundReference)
right:1(DpuLiteral)
DpuNotNull是一个一元表达式，
DpuEqualTo是一个Binary表达式，例如，id=1，id是DpuBoundReference(它对batch的执行就是根据列序号得到指定的列)，1是Literal

projectSingle的逻辑： 
首先是树根(也就是DpuAnd)对batch计算，也就是调用Dpu表达式公共接口的columnarEval方法，DpuAnd是一个DpuBinaryExpression，对于DpuBinaryExpression的计算，是先计算左右子树，再计算自己。
本例中left就是DpuNotNull，它是一个一元表达式， 经过columnarEval→doItColumnar→doColumnar最终调用RuntimeFunctionJNI的unaryOperation, 最后，再把RaceCV转为DpuCV

>此时的unaryOperation是NOT_NULL

```
trait RaceUnaryExpression extends DpuUnaryExpression {
  def unaryOperation: UnaryOperator

  override def doColumnar(input: DpuColumnVector): RaceColumnVector = {
    if (isBinaryOrUnaryChildren(children)) {
      withResource(input) { input =>
        input.getRaceColumnVector.unaryOperation(unaryOperation, outputTypeOverride)
      }
    } else {
      input.getRaceColumnVector.unaryOperation(unaryOperation, outputTypeOverride)
    }
  }
}
```


然后计算right, 即EqualTo, 它也是一个DpuBinaryExpression， 继续递归计算left , right:
DpuBoundReference的columnarEval,实现就是按照序号从batch中取出一列
DpuLiteral的实现更简单，就是转为Array[Byte]

接着计算EqualTo这个二元表达式，对left调用JNI接口。

最后，再回到DpuAnd根节点上来，会匹配到case *(*l: DpuColumnVector, r: Array*[*Byte*])  *这个case, 调用DpuAnd的doColumnar方法，最终调用ColumnDataManagementJNI的binaryOperation方法，得到一个RaceColumnVector列(布尔型，作为过滤的mask列)。

>这里传入的Operator是BIT_AND, 输出类型outpoutTypeOverride是布尔类型，这在DpuAnd算子中有定义，Race支持的所有列值操作见ColumnValueOperator类


提取batch所有列构成RaceTable, 调用RaceTable的filterRaceTable方法，传入mask。

>这里会把DataType转为RaceDataType

Race列数组初始化得到ColumnDataManagementJNI 结果handle数组， 逐列调用JNI接口完成过滤：

RuntimeFunctionJNI.*binaryOperation(*operateHandles*[*index*]*, this.columnHandle, ColumnColumnOperator.*MASK_REDUCE*, resultHandles*[*index*]*.getHandle*())*;


### 一元算子: DpuProjectExec

核心逻辑：

1. 对子节点生成的RDD做map
2. 多个DpuBoundReference表达式逐个从batch里project一个列，然后构成一个新的batch



## (三)其他

### ColumnBatch

根据列序号获取指定列

```
*/**
 * Returns the column at `ordinal`.
 */
*public ColumnVector column(int ordinal) { return columns[ordinal]; }
```




### DpuExpressionsUtils 

def getTrimString*(*trimStr: Option*[*Expression*])*: String 
说明： DpuLiteral转String
def columnarEvalToColumn*(*expr: Expression, batch: ColumnarBatch*)*: DpuColumnVector
对表达式计算出一个单列DpuColumnVector



### RaceColumnVector

代表DPU设备上的一个数据列，对该列提供一元和二元运算操作，例如一元操作:

```
public enum UnaryOperator {
    NEGATIVE(111),
    IS_NULL(121),
    NOT_NULL(122);
    public final int id;
    private UnaryOperator(int id) {
        this.id = id;
    }
}
```

二元操作equalTo， 这些操作通过RuntimeFunctionJNI实现
