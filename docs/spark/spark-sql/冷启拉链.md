```scala


import org.apache.spark.sql.functions.col
import org.apache.spark.sql.types._
import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}
import org.apache.spark.storage.StorageLevel

/**
  * 冷起 active info 拉链表
  */
object ChainBackUp {
  def main(args: Array[String]): Unit = {
    val Array(input_path:String,out_info_path:String,out_active_path:String) = args

    import org.apache.spark.sql.functions._
    val spark = SparkSession.builder()
//      .master("local[2]")
      .config("spark.sql.sources.partitionOverwriteMode","dynamic")
      .getOrCreate()

    val base_cols = "app_id, distinct_id, platform,channel,app_ver,model,os_ver,country,province,city,date,time,is_dau"
    // 读取
    val base_data = spark.read.parquet(input_path)
      .selectExpr(base_cols.split(",") : _*)
      .where("is_dau=1 and distinct_id !='' and distinct_id is not null and platform !='' and platform is not null")
        .withColumn("date",col("date").cast(LongType))
      .withColumn("app_id",col("app_id").cast(LongType))
      .persist(StorageLevel.MEMORY_AND_DISK)

    base_data.printSchema()
    val base_active = base_data.selectExpr("app_id,distinct_id,platform,date,time".split(","):_*)
    active(base_active,out_active_path)
    info(base_data,out_info_path)
  }

  private [this] def active(data:DataFrame,to_path :String): Unit ={

    data.createOrReplaceTempView("base_data")
    data.sqlContext.sql("select app_id,distinct_id,date,platform,date,MAX(time) last_tm from base_data group by date,distinct_id,app_id,platform")
      .createOrReplaceTempView("active_data")

    val final_data = data.sqlContext.sql("""select distinct_id,
                          |       platform,
                          |       MIN(date) OVER(PARTITION BY distinct_id,platform) AS first_day,
                          |       date AS last_day,
                          |       from_unixtime(last_tm,'yyyy-MM-dd HH:mm:SS') as last_tm,
                          |       date as start_day,
                          |       from_unixtime(unix_timestamp(),'yyyy-MM-dd HH:mm:SS') as etl_time ,
                          |       LEAD(date, 1, 20991231) OVER( PARTITION BY distinct_id,platform ORDER BY date) AS end_day,
                          |       app_id
                          |       from active_data
                          |       """.stripMargin)
      .repartition(15)
    final_data.write.partitionBy("end_day","app_id").mode(SaveMode.Overwrite).parquet(to_path)
  }

  
// 套路： 建临时表通过sql操作再建临时表，后面还可以用sql操作  
  private [this] def info(data:DataFrame,to_path :String): Unit ={
    data.createOrReplaceTempView("base_data")
    data.sqlContext.sql(
      """
        |SELECT
        |  app_id,
        |distinct_id,
        |       platform,
        |       channel,
        |       app_ver,
        |       model,
        |       os_ver,
        |       country,
        |       province,
        |       city,
        |       date,
        |       MD5(CONCAT(NVL(channel, ''), NVL(app_ver, ''), NVL(model, ''), NVL(os_ver, ''), NVL(country, ''), NVL(province, ''), NVL(city, ''))) AS change_code,
        |       ROW_NUMBER() OVER(PARTITION BY date, distinct_id, platform ORDER BY time DESC) AS rn
        |FROM   base_data
      """.stripMargin)
      .where("rn = 1")
      .createOrReplaceTempView("active_data")

    data.sqlContext.sql(
      """
        |SELECT distinct_id,
        |       platform,
        |       channel,
        |       app_ver,
        |       model,
        |       os_ver,
        |       country,
        |       province,
        |       city,
        |       date AS start_day,
        |       from_unixtime(unix_timestamp(), 'yyyy-MM-dd HH:mm:ss') as etl_tm,
        |       LEAD(date, 1, 20991231) OVER(PARTITION BY distinct_id ORDER BY date) AS end_day,
        |       app_id
        |FROM   (SELECT app_id,
        |              date,
        |               distinct_id,
        |               platform,
        |               channel,
        |               app_ver,
        |               model,
        |               os_ver,
        |               country,
        |               province,
        |               city,
        |               change_code,
        |               LAG(change_code, 1, '@@@') OVER(PARTITION BY distinct_id ORDER BY date) AS lag_change_code
        |        FROM   active_data
        |        ) t
        |WHERE  change_code != lag_change_code
      """.stripMargin)
      .repartition(15)
    // 列类型转换
      .withColumn("end_day",col("end_day").cast(LongType))
    // 输出
      .write.partitionBy("end_day","app_id").mode(SaveMode.Overwrite).parquet(to_path)
  }
}

```



> 注意：
>
> `arr:_*` tells the compiler to pass each element of arr as its own argument to func , rather than all of it as a single argument.





