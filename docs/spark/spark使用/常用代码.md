# 创建rdd

```scala
sc.parallelize(Array("sun","mon","tue","wed","thu","fri"),4)

var b=List.empty[(String,String)]
b=b:+(("x","z"))
```



```scala

time_info_dict.asScala.toMap
```



用class读取parquet文件:

```scala
import com.xiaomi.bigdata.oneid.social.base.util.HDFSUtils.{OutputOverwriteParquetWrapper, SparkContextThriftFileWrapper}
 val pad_wifi_edge: RDD[DwmOneidEdgeDf] = spark.sparkContext.thriftParquetFile(pad_wifi_path, classOf[DwmOneidEdgeDf])

写parquet文件
res_edge.saveAsParquetOverwrite(out+s"/date=$day/edge_type=mac_wifi")
```







# 写text

```scala
 val res = List(
      "20210403","20210404","20210405"
      ,"20210501","20210502","20210503","20210504","20210505"
      ,"20210612","20210613","20210614"
      ,"20210919","20210920","20210921"
      ,"20211001","20211002","20211003","20211004","20211005","20211006","20211007"

      ,"20211231","20220101","20220102"
      ,"20220131","20220201","20220202","20220203","20220204","20220205","20220206"
      ,"20220403","20220404","20220405"
      ,"20220501","20220502","20220503","20220504","20220505"
      ,"20220603","20220604","20220605"
      ,"20220909","20220910","20220911"
      ,"20221001","20221002","20221003","20221004","20221005","20221006","20221007"
    )
      spark.sparkContext.parallelize(res)
        .toDF("holiday")
      .write
    .mode(SaveMode.Overwrite)
      .text("holiday.txt")
```

