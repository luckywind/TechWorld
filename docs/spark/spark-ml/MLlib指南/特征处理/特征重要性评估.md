

### 线性分类模型特征重要性

[参考](https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model)

特征重要性可参考： 特征标准差*特征系数

```python
import numpy as np    
from sklearn.linear_model import LogisticRegression

x1 = np.random.randn(100)
x2 = 4*np.random.randn(100)
x3 = 0.5*np.random.randn(100)
y = (3 + x1 + x2 + x3 + 0.2*np.random.randn()) > 0
X = np.column_stack([x1, x2, x3])

m = LogisticRegression()
m.fit(X, y)

# The estimated coefficients will all be around 1:
print(m.coef_)

# Those values, however, will show that the second parameter
# is more influential
print(np.std(X, 0)*m.coef_)
```



spark ml 中可以这样获得系数向量：

```scala

    val splitModel: TrainValidationSplitModel = model.stages.last.asInstanceOf[TrainValidationSplitModel]
   println(splitModel)
    val coefficients: Vector = splitModel.bestModel.asInstanceOf[LogisticRegressionModel].coefficients
    println(coefficients)
```





### 树模型特征重要性

这里找到一个树模型的特征重要性评估[代码](https://github.com/riversun/spark-ml-feature-importance-helper).Spark 提供了树模型的特征重要性

```scala
  /**
   * Estimate of the importance of each feature.
   *
   * Each feature's importance is the average of its importance across all trees in the ensemble
   * The importance vector is normalized to sum to 1. This method is suggested by Hastie et al.
   * (Hastie, Tibshirani, Friedman. "The Elements of Statistical Learning, 2nd Edition." 2001.)
   * and follows the implementation from scikit-learn.
   *
   * @see `DecisionTreeRegressionModel.featureImportances`
   */
  @Since("1.5.0")
  lazy val featureImportances: Vector = TreeEnsembleModel.featureImportances(trees, numFeatures)
```



### Demo

```scala
  val featureCols = Array("medage", "medincome", "roomsPhouse", "popPhouse", "bedrmsPRoom", "longitude", "latitude")

    //put features into a feature vector column
    val assembler = new VectorAssembler().setInputCols(featureCols).setOutputCol("rawfeatures")
    val scaler = new StandardScaler().setInputCol("rawfeatures").setOutputCol("features").setWithStd(true).setWithMean(true)

    val rf = new RandomForestRegressor().setLabelCol("medhvalue").setFeaturesCol("features")

    val steps =  Array(assembler, scaler, rf)

    val pipeline = new Pipeline().setStages(steps)

    val paramGrid = new ParamGridBuilder()
      .addGrid(rf.maxBins, Array(50, 100, 200))
      .addGrid(rf.maxDepth, Array(2, 5, 10))
      .addGrid(rf.numTrees, Array(5, 10, 20))
      .build()

    val evaluator = new RegressionEvaluator()
      .setLabelCol("medhvalue")
      .setPredictionCol("prediction")
      .setMetricName("rmse")

    val crossvalidator = new CrossValidator()
      .setEstimator(pipeline)
      .setEvaluator(evaluator)
      .setEstimatorParamMaps(paramGrid).setNumFolds(3)

    val pipelineModel = crossvalidator.fit(trainingData)

    val rfm = pipelineModel
      .bestModel.asInstanceOf[PipelineModel]
      .stages(2)
      .asInstanceOf[RandomForestRegressionModel]

    val featureImportances = rfm.featureImportances

    assembler.getInputCols
      .zip(featureImportances.toArray)
      .sortBy(-_._2)
      .foreach {
        case (feat, imp) =>
          println(s"feature: $feat, importance: $imp")
      }

```

