

### 线性分类模型特征重要性

[参考](https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model)

特征重要性可参考： 特征标准差*特征系数

```python
import numpy as np    
from sklearn.linear_model import LogisticRegression

x1 = np.random.randn(100)
x2 = 4*np.random.randn(100)
x3 = 0.5*np.random.randn(100)
y = (3 + x1 + x2 + x3 + 0.2*np.random.randn()) > 0
X = np.column_stack([x1, x2, x3])

m = LogisticRegression()
m.fit(X, y)

# The estimated coefficients will all be around 1:
print(m.coef_)

# Those values, however, will show that the second parameter
# is more influential
print(np.std(X, 0)*m.coef_)
```



spark ml 中可以这样获得系数向量：

```scala

    val splitModel: TrainValidationSplitModel = model.stages.last.asInstanceOf[TrainValidationSplitModel]
   println(splitModel)
    val coefficients: Vector = splitModel.bestModel.asInstanceOf[LogisticRegressionModel].coefficients
    println(coefficients)
```





### 树模型特征重要性

这里找到一个树模型的特征重要性评估[代码](https://github.com/riversun/spark-ml-feature-importance-helper).Spark 提供了树模型的特征重要性

```scala
  /**
   * Estimate of the importance of each feature.
   *
   * Each feature's importance is the average of its importance across all trees in the ensemble
   * The importance vector is normalized to sum to 1. This method is suggested by Hastie et al.
   * (Hastie, Tibshirani, Friedman. "The Elements of Statistical Learning, 2nd Edition." 2001.)
   * and follows the implementation from scikit-learn.
   *
   * @see `DecisionTreeRegressionModel.featureImportances`
   */
  @Since("1.5.0")
  lazy val featureImportances: Vector = TreeEnsembleModel.featureImportances(trees, numFeatures)
```



