[官方文档](https://spark.apache.org/docs/3.1.2/ml-pipeline.html)

ml pipeline提供了一个基于Dataframe的统一的高级API集合，帮助创建、调优机器学习pipelines

# 主要概念

MLlib中机器学习算法相关的标准API使得其很容易组合多个算法到一个pipeline或者工作流中，这一部分包括通过Pipelines API介绍的主要概念，以及是从sklearn的哪部分获取的灵感；

- DataFrame：这个ML API使用Spark SQL中的DataFrame作为ML数据集来持有某一种数据类型，比如一个DataFrame可以有不同类型的列：文本、向量特征、标签和预测结果等；
- Transformer：转换器是一个可以将某个DataFrame转换成另一个DataFrame的算法，比如一个ML模型就是一个将DataFrame转换为原DataFrame+一个预测列的新的DataFrame的转换器；
- Estimator：预测器是一个可以fit一个DataFrame**得到一个转换器的算法**，比如一个学习算法是一个使用DataFrame并训练得到一个模型的预测器；
- Pipeline：一个Pipeline链使用多个转换器和预测器来指定一个机器学习工作流；
- Parameter：所有的转换器和预测器通过一个通用API来指定其参数；

## Pipeline组件

### Transformers - 转换器

转换器是包含特征转换器和学习模型的抽象概念，严格地说，转换器需要实现transform方法，该方法将一个DataFrame转换为另一个DataFrame，通常这种转换是通过在原基础上增加一列或者多列，例如：

- 一个特征转换器接收一个DataFrame，读取其中一列（比如text），将其映射到一个新的列上（比如feature vector），然后输出一个新的DataFrame包含映射得到的新列；
- 一个学习模型接收一个DataFrame，读取包含特征向量的列，为每个特征向量预测其标签值，然后输出一个新的DataFrame包含标签列；

### Estimators - 预测器

一个预测器是一个学习算法或者任何在数据上使用fit和train的算法的抽象概念，严格地说，一个预测器需要实现fit方法，该方法接收一个DataFrame并产生一个模型，该模型实际上就是一个转换器，例如，逻辑回归是一个预测器，调用其fit方法可以得到一个逻辑回归模型，同时该模型也是一个转换器；

### Pipeline组件属性

转换器的transform和预测器的fit都是无状态的，未来可能通过其他方式支持有状态的算法；

每个转换器或者预测器的实例都有一个唯一ID，这在指定参数中很有用；

### Pipeline

在机器学习中，运行一系列的算法来处理数据并从数据中学习是很常见的，比如一个简单的文档处理工作流可能包含以下几个步骤：

- 将每个文档文本切分为单词集合；
- 将每个文档的单词集合转换为数值特征向量；
- 使用特征向量和标签学习一个预测模型；

MLlib提供了工作流作为Pipeline，包含一系列的PipelineStageS（转换器和预测器）在指定顺序下运行，我们将使用这个简单工作流作为这一部分的例子；

#### 如何工作

一个Pipeline作为一个特定的阶段序列，每一阶段都是一个转换器或者预测器，这些阶段按顺序执行，输入的DataFrame在每一阶段中都被转换，对于转换器阶段，transform方法作用于DataFrame，对于预测器阶段，fit方法被调用并产生一个转换器（这个转换器会成为Pipeline模型的一部分或者成为一个fitted pipeline），该转换器的transform方法同样作用于DataFrame上；

下图是一个使用Pipeline的简单文档处理工作流：

![ML Pipeline Example](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/ml-Pipeline.png)

上图中，上面那一行代表一个包含三个stage的Pipeline.前面两个蓝色的是Transformers，第三个是一个Estimator。  下面那一行代表通过pipeline的数据流(DataFrame).Pipeline.fit()方法在最原始的包含原始文档和label的Dataframe上调用，Tokenizer.transform()方法把原始文档切分未单词，并给Dataframe增加一个包含单词的列。 HashingTF.transform()方法把单词列转换为特征向量并加入到dataframe中。 至此，因为LogisticRegression是一个Estimator， Pipeline首先调用LogisticRegression.fit()来产生一个LogisticRegressionModel。如果Pipeline包含多个Estimator，则在把dataframe传给下一个stage之前会调用 `LogisticRegressionModel`’s `transform()`方法。

Pipeline本身是一个Estimator,因此，在Pipeline.fir()方法调用后，产生一个PipelineModel(是一个Transformer), PipelineModel在测试时间使用，下图解释了用法：

![ML PipelineModel Example](https://piggo-picture.oss-cn-hangzhou.aliyuncs.com/image/ml-PipelineModel.png)

上图，PipelineModel和原始的Pipeline有相同的stage，只是原pipeline的所有Estimator现在变成了Transformer。 当在测试集上调用PipelineModel`’s `transform()方法时，数据会按照顺序通过fitted pipeline。

`Pipeline`s 和 `PipelineModel`s 有助于确保训练集和测试集通过相同的特征处理步骤。

## 细节

*DAG `Pipeline`s* : pipeline的stage通过一个有序数组指定。现在的例子是线性pipeline,即每个stage使用上一个stage产出的数据。事实上，只要数据流图构成一个DAG，是可以创建非线性pipeline的，当前，通过指定每个stage的输出/输出列来形成DAG。

*Runtime checking*： 因为pipeline可一操作可变类型，无法使用编译时类型检查。`Pipeline`s 和 `PipelineModel`在真正运行pipeline时做运行时检查，这用到了dataframe的schema。

*Unique Pipeline stages*： 一个stage不能出现两次，每个stage必须有一个唯一的ID。但是不同的实例(有不同的ID)是可以出现两次的。

## Parameters

MLlib `Estimator`s 和 `Transformer`s 使用统一的API来指定参数

Param指定命名参数，ParamMap指定k_v类型参数。 有两种主要的方法传递参数给算法:

1. 对实例指定参数. 例如，lr.setMaxIter(10)
2. 传递一个ParamMap给fit()或者transform()

参数属于指定的`Estimator`s / `Transformer`s.实例，例如，我们有两个LogisticRegression实例，lr1和lr2，我们可以这样指定maxIter参数：ParamMap(lr1.maxIter -> 10, lr2.maxIter -> 20)

## 保存/加载pipeline

## 模型选择

