# 自我介绍

面试官您好！非常荣幸参与贵公司大数据开发职位的应聘， 我是程幸福，今年31岁，对大数据技术、数据分析有强烈的兴趣，且对流行的Spark技术框架非常熟悉，有很多源码分析经验，以及实践经验。  目前就职于小米科技，担任大数据研发工程师；本次离职主要原因是公司组织架构和组内业务变动很大，与个人职业规划有较大出入。本科毕业于安庆大学数学系，研究生毕业于武汉大学数学与统计学院概率论与数理统计专业。2016年参加工作，至今已有7年工作经验。接下来我简要提两个工作经历：

1. 2016年到2018年在烽火科技担任大数据研发工程师，负责HBase的存储和查询框架设计，并发表专利。

   核心亮点： 

   l 依据业务特点设计RowKey结构，通过二级索引方案支持多种数据索引

   l 通过预分区避免数据读写热点

   l 通过自定义负载均衡算法，增加对IndexTable Region的分配控制。以相同的StartKey作为IndexTable Region和DataTable Region的关联依据，将IndexTable Region和与其对应的DataTable Region分配到同一个RegionServer，减少跨机器读取开销  

2. 2018年到2020年就职于绿盟科技武汉研发中心，担任大数据平台架构师，团队有7人。负责大数据平台的设计和开发工作。负责模块划分、功能拆解；大数据组件Spark、SparkStreaming、Kafka等的调研与应用

2. 2020年至今在小米OneID项目组，负责小米的设备ID、用户ID以及家庭ID的设计与开发工作，对对OneID有更加深入的理解并形成经验，同时对Spark生态中的Core模块、图计算模块、机器学习模块有更加深入的理解。 利用图计算帮助数据工场统计数据血缘图中每个表的父级数据量

以上是我个人的一个简短介绍



# 团队管理经验

1. <font color=red>明确每个人的职责</font>
   同一个项目只能有一个最终负责人；这样出了问题，大家都清楚谁应该出来承担责任，取得成绩，谁的功劳也更清晰

2. <font color=red>明确的目标</font>

   与组员对齐目标，数理工作中的困难点。没有一致的方向，再优秀的团队也不会拿出好的结果

3. <font color=red>明确的授权和资源</font>
   作为团队负责人，一个重要的职责就是为下属解决他解决不了的问题，即权力和资源

4. <font color=red>适当的中间结果检查</font>

5. <font color=red>要结果，不要借口</font>

   工作上的事情只有两个结果：搞定，或者没搞定。 如果没搞定，需要复盘损失是什么？是否有弥补的办法？需要什么帮助？

6. 不断改善
   不断优化管理规则

# 面试记录

## 民生科技(x)

12.21晚7点

平薪/10%涨幅

driver端内存划分，Executor端内存划分；driver内存使用。 排查方法，代码自动debug的方法

Java调优指令

SpingBoot的优势

>  1227完成在线测评

月base? 总包会平摊到多少月？

五险一公积金缴存比例？

有晋升路线吗？

餐补等福利？



通过一些资料以及咨询了一下我的同事，对咱们公司也有个大概的解了，从我的到的消息来看，对于一个7年的硕士来说，年包35确实低了，一般硕5能拿到40。

在你之前其他面试都被我推了，感觉你比较爽快，我顶着发烧接了这个面试，我们算是有缘的，我一定要拿到这个机会， 我还是希望跟您好好谈一谈，要说我现在的待遇，31是最低包，每年有晋升机会。 我期望年包38，这个涨幅只有15%；

31w的基础20%的涨幅，37w

二面准备：

1. 对民生科技的理解，为什么选择民生科技

​        武汉研发中心这边刚刚成立，现在处于快速扩张期，接下来一定会有很多的事情，我觉得这是一个机会；同时本人换工作是非常谨慎的，在当前这个大环境下， 我也希望下家公司是稳定靠谱的，所以我希望这个时候加入，与公司共同成长。

性格测评挂了        



伴伴：

伴伴大数据组件：hive、spark、flink、clickhouse 等，偏上层一些

看中大数据组件了解的深入度和广度

先是问项目，然后问了一些组件和 java 方面的

问的 flink、数据方面的底层原理、业务场景

Flink 建模





## 立得1223：

spark 与Flink各有什么特点？有什么区别？ spark的持久化机制，kafka

spark调优经验：

要做数据中台，但目前就一个大数据开发，预计半年扩到5-6个人； 非结构化数据。 后序有笔试：sql+大数据框架概念

1226:一面通过，发笔试链接

 问题: springboot与spring有什么优势？

0105二面

HBase二级索引、平台、OneID

> 1. 自定义负载均衡算法，以startRowKey为分组依据，把IndexTable的Region与数据表的Region分配到同一个节点上，会不会导致负载不均衡？不会，索引Region和数据Region是一一对应的，数据表Region的负载均衡我们不干预，只要数据表Region是均衡的，索引表自然就均衡(一一对应且是局部索引)
> 2. 数据写入流程
> 3. 宕机容错

0110三面



## 腾讯地图

1226: 7-8分

1. 业务理解、表达能力欠缺
2. 简历需要更加丰富

1229号二面：
[删除链表重复元素](https://blog.csdn.net/duan20140614/article/details/125722684)

多线程操作syschronize方法，后台线程； 二叉树遍历、递归/非递归两种版本

0109

996190522

项目难点、项目优化方法、数仓分层理论    



## 拼多多x

两个升序数组中，找到和最小的k个对儿，[每个对儿分别来自两个数组](https://blog.csdn.net/realmagician/article/details/16902927)。

[查找和最小的K对数字(伪暴力法&优先队列)](https://blog.csdn.net/qq_38737428/article/details/122540276?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-122540276-blog-119053057.pc_relevant_3mothn_strategy_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-122540276-blog-119053057.pc_relevant_3mothn_strategy_recovery&utm_relevant_index=2)



## 容知日新x

1229

> SparkStreaming+Kafka，接收设备日志，进行异常诊断。团队加运维12人

0103

6:00 三段经历，大厂经历。主要问数据量

0106三面HR经理

> 主要聊离职原因，职业规划

0109号反馈：能力认可，但综合对比有更合适的人选，流程先暂停

> 目前已有的offer不要说太多，否则会认为你没有规划，找到哪个是哪个，可以说1到2个                                                                                                        

## 美的：

笔试0103: 

1. 星型模型和雪花模型的区别和应用
2. 数仓分层，各层职责
3. 输出什么？

```java
obj是null
  if obj=null
     System.out.print(true)
  else     
     System.out.print(false)
```

2:00 面试： 武汉是物流团队，30人左右，全国有2-300人， 上班时间9:00-6:00 制造业公司。







## 金山云:

0104

1. 催促光谷人工智能研究院，院长

2. 催促民生科技二面

3. 催促小红书安排一面 x

4. 金山云一面

   > 8大 组100多号人， 调度组、离线计算、实时计算组。。  明年搬到光谷天地逐渐超过北京。 主要关注我在绿盟带人的经验，spark源码修改的经验。
   >
   > 蔡想面的早，金山云问了我职级低原因，蔡想:因为组织调整的原因。

0106二面

1. 项目
2. 数据接入流程
3. synchronize在静态方法和普通方法上的区别
4. 双亲委派模型
5. 任务调度系统
6. 持续集成的了解
7. Join的优化
8. Flink的反压机制
8. 十亿数据TopN方式：

0109 临时沟通，15薪 300餐补，五险一金全额缴，早10晚7，涨幅可能没那么高

> 蔡想2面技术面已发offer，涨幅10%左右(29k左右?)
>
> 预约10号下午3点，大数据负责人终面：一二面面试官的领导

## 小红书(x)

0106一面

```sql
现在有一张用户下单明细记录表（包含30天的用户下单数据）
dwd_ord_detail_df
(
uid string comment '用户ID', 
oid string comment '订单ID', 
dtm string comment '下单时间，格式：YYYY-MM-DD HH:mm:ss'
)
求每个用户的最长连续下单天数
要求：
1、考虑多段连续下单的场景
2、过滤掉非连续多天下单用户
3、函数名如果忘记，可以随便写一个代替，最后解释一下即可
4、请直接在题目下方写出实现SQL

with t as (
select uid, date_sub(order_date,rn) as diff
from (
select uid,oid,dtm,row_number()over(partition by uid order by dtm) as rn,
	date(dtm) order_date from dwd_ord_detail_df
))
select uid,diff, count(1)cnt from t group by uid,diff 
having cnt>1 ;


with t as (
select 
uid,order_date, row_number()over(partition by uid order by order_date) as rn
  from 
(select uid,date(dtm)order_date from dwd_ord_detail_df group by  uid,date(dtm))-- 去重
),
a as (
select uid,date_sub(order_date,rn) as diff  from t -- 连续日期的开始日期 
),
b as (select uid,diff , count(1) cnt from a group by uid,diff having cnt>1)
select uid,max(cnt) from b group by uid;
```



kyuubi

## 光谷人工智能研究院(年后开始)

## ali

视频云

1. java多线程

2. volatile

3. final\finalize\finally

   1.final是一个关键字，如果我们用final来修饰属性的话，**属性不可以改变**，所以被final修饰的属性必须在声明的时候设置一个初始值，在之后需要用到的地方只能读取该值，不能对该属性做出改变，**final修饰方法的话，方法可以被使用，但是不能被重写，final修饰类的话，类不能被继承**，也就是说该类不能有子类，所以我们不能final来修饰一个抽象类。

   2.finally是java的异常处理机制，我们经常会将finally语句放在try...catch...语句后面作为一种补充，因为finally语句不管代码有没有异常都会执行，这样我们可以用finally语句维护对象内部状态，清理非内存操作，例如我们可以使用finally语句来关闭流或者数据库等操作。

   3.finallize方法是java.lang.Object里面定义的，因为Object是所有类的基类，所以我们可以理解为每个对象都有finalize方法，finalize的主要目的是在不可撤销的丢弃对象之前执行清除操作，<font color=red>对于给定的任何对象，java虚拟机最多只调用一次finalize()方法，finalize()方法是垃圾回收器删除对象之前对这个对象调用的。</font>

4. 单例模式饿汉式/懒汉式，volatile的作用
   [参考](https://blog.csdn.net/mqdxiaoxiao/article/details/126564081)
   禁止JVM进行指令重排； Java在new创建对象时，有三条指令:

   - 分配内存空间
   - 初始化对象
   - 变量指向对象

   由于JVM指令重排，可能对象还未初始化就被赋给变量了， 其他线程拿到的是未初始化的对象，导致异常。

5. 关系数据库删除大量数据可能会遇到什么问题？ 

6. 说一下spark shuffle优化、group by数据倾斜的处理

7. 说一下flink checkpoint机制

8. 力扣： 链表按k个一组进行翻转

# spark

## 优化

1. 并行度优化
   1. 增加executor个数提升并行能力
   2. 增加分区数
2. Join优化
   1. 采用广播器进行Join代替shuffle Join
   2. 让两个RDD共享分区器避免shuffle Join
3. 缓存优化
   1. 公用RDD进行缓存
   2. checkpoint的使用，需要ck的RDD尽量先缓存
4. 算子优化
   1. reduceByKey代替groupByKey
5. 调节数据本地性等待时长

TaskScheduler在进行分配之前都会计算出 每一个task最优计算位置。Spark的task的分配算法优先将task发布到数据所在的节点上 ，从而达到数据最优计算位置。在spark中共有几种数据本地化级别：
1、PROCESS_LOCAL：数据和计算它的代码在**同一个JVM进程**中。
2、NODE_LOCAL：数据和计算它的代码在**一个节点上**，但是不在一个进程中，比如在不同的executor进程中，或者是数据在HDFS文件的block中。
3、NO_PREF：数据从哪里过来，性能都是一样的。例如，读取mysql数据库
4、RACK_LOCAL：数据和计算它的代码在一个机架上。
5、ANY：数据可能在任意地方，比如其他网络环境内，或者其他机架上

Spark倾向于使用最好的本地化级别来调度task，但是这是不可能的。如果没有任何未处理的数据在空闲的executor上，那么Spark就会放低本地化级别。这时有两个选择：第一，等待，直到executor上的cpu释放出来，那么就分配task过去；第二，立即在任意一个executor上启动一个task。

Spark默认会等待一会儿，来期望task要处理的数据所在的节点上的executor空闲出一个cpu，从而将task分配过去。只要超过了时间，那么Spark就会将task分配到其他任意一个空闲的executor上。

可以设置参数，spark.locality系列参数，来调节Spark等待task可以进行数据本地化的时间。

## ck

<font color=red>需要ck的RDD事先进行缓存，增加ck的速度，因为ck会在正常job执行完成后专门启用一个job进行ck。如果该RDD进行了cache,则ck的job直接读取缓存，从而提升性能。</font>

cache和checkpoint都可以起到减少重复计算的作用。但区别还是比较大的：

1. **目的不同**：缓存的目的是加速计算，ck的目的是作业失败后快速恢复
2. **存储性质和位置不同**：缓存主要食用内存，偶尔食用硬盘；ck主要使用HDFS
3. **写入速度和规则不同**: 缓存较快，对job的执行影响较小，ck写入速度慢，因此启用专门的job进行持久化
4. **对数据血缘的影响不同**： cache如果放到内存，可能会因为节点失败导致分区丢失，还是需要重新计算，这样就必须保留血缘。而checkpoint是把rdd写入文件系统了，节点失败也不会导致重算，因此是直接切断了血缘。
5. **应用场景不同**： 缓存适合多次读取、占用空间不是非常大的RDD，ck适用于依赖关系比较复杂、重算代价高的RDD。
6. cache即使使用persist(StorageLevel.DISK_ONLY) 与 checkpoint 也有区别。前者虽然可以将 RDD 的 partition 持久化到磁盘，但该 partition 由 blockManager 管理。一旦 driver program 执行结束，也就是 executor 所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，被 cache 到磁盘上的 RDD 也会被清空（整个 blockManager 使用的 local 文件夹被删除）。 但是checkpoint的内容以被下一个 driver program 使用。

