# 自我介绍

面试官您好！非常荣幸参与贵公司大数据开发职位的应聘， 我是程幸福，今年31岁，对大数据技术、数据分析有强烈的兴趣，且对流行的Spark技术框架非常熟悉，有很多源码分析经验，以及实践经验。  目前就职于小米科技，担任大数据研发工程师；本次离职主要原因是公司组织架构和组内业务变动很大，团队业务少，趋于维稳状态；与个人职业规划有较大出入。本科毕业于安庆大学数学系，研究生毕业于武汉大学数学与统计学院概率论与数理统计专业。2016年参加工作，至今已有7年工作经验。接下来我简要提两个工作经历：

1. 2016年到2018年在烽火科技担任大数据研发工程师，负责HBase的存储和查询框架设计，并发表专利。

   核心亮点： 

   l 依据业务特点设计RowKey结构，通过二级索引方案支持多种数据索引

   l 通过预分区避免数据读写热点

   l 通过自定义负载均衡算法，增加对IndexTable Region的分配控制。以相同的StartKey作为IndexTable Region和DataTable Region的关联依据，将IndexTable Region和与其对应的DataTable Region分配到同一个RegionServer，减少跨机器读取开销  

2. 2018年到2020年就职于绿盟科技武汉研发中心，担任大数据平台架构师，团队有7人。负责大数据平台的设计和开发工作。负责模块划分、功能拆解；大数据组件Spark、SparkStreaming、Kafka等的调研与应用

2. 2020年至今在小米OneID项目组，负责小米的设备ID、用户ID以及家庭ID的设计与开发工作，对对OneID有更加深入的理解并形成经验，同时对Spark生态中的Core模块、图计算模块、机器学习模块有更加深入的理解。 利用图计算帮助数据工场统计数据血缘图中每个表的父级数据量

以上是我个人的一个简短介绍

# 项目难点及如何解决的

1. 家庭ID：
   1. 路由器ID稳定性问题： 一个路由器可以有多个频段，且用户可以修改Wi-Fi名称导致路由器ID变化，如何延续之前的ID？
      - 挖掘策略，使得统一个路由器的Wi-Fi之间建立联系
      - 利用连通图算法，生成一个唯一ID，其他ID和唯一ID建立映射关系
      - 关联历史ID，能关联上的的进行延续
   2. 家庭有多个路由器的问题： 家庭新增、更换路由器
      - 挖掘策略，给同一个家庭里的路由器建立关系
   3. 大型连通图遍历慢
      - Spark连通图算法是一个宽度遍历，当类似环形的大型连通图，需要遍历很多轮才能找到最小的那个顶点。  解决办法是，重构这个连通图，中心点是最小的顶点，其他点直接连接到这个点上，再送入连通图算法
      - 控制迭代次数
      - 排除异常数据，例如售后维修点、工厂测试等场景
   4. 30亿边、15亿顶点的大型图，运行缓慢
      - 定期checkpoint解决节点失败导致的重算
      - join优化，改变RDD的分区方式，使得join的两个RDD使用同一个分区器，避免了shuffle
      - 广播小RDD避免shuffle
      - 优化数据本地性等待时长
   5. 家庭、学校、公司的识别
      - 缺乏样本数据，联合兄弟部门进行标注，获得样本，训练模型识别
      - 通过Wi-Fi识别
      - <font color=red>模型优化，我们采用的是二分类模型，需要设置一个合适的阈值,人工选择费时费力，还比较难选择到最优的阈值。使用模型评估器设计自动选择模型的方法</font>
   6. 除了对内置算法进行调优外，还基于Pregel模型，实现自定义的图算法满足业务需要
      例如数据血缘的计算

# 团队管理经验

1. <font color=red>明确每个人的职责</font>
   同一个项目只能有一个最终负责人；这样出了问题，大家都清楚谁应该出来承担责任，取得成绩，谁的功劳也更清晰

2. <font color=red>明确的目标</font>

   与组员对齐目标，数理工作中的困难点。没有一致的方向，再优秀的团队也不会拿出好的结果

3. <font color=red>明确的授权和资源</font>
   作为团队负责人，一个重要的职责就是为下属解决他解决不了的问题，即权力和资源

4. <font color=red>适当的中间结果检查</font>

5. <font color=red>要结果，不要借口</font>

   工作上的事情只有两个结果：搞定，或者没搞定。 如果没搞定，需要复盘损失是什么？是否有弥补的办法？需要什么帮助？

6. 不断改善
   不断优化管理规则

## 离职原因

组织架构调整，leader给机会转岗，但没能领会，结果业务组解散

## 规划

继续做技术类工作，做架构师，技术顾问等工作。

## 有什么问题

1. 贵公司对新入公司的员工有没有什么培训项目，我可以参加吗？

2. 或者说贵公司的晋升机制是什么样的？。

# 面试记录

## 民生科技(x)

12.21晚7点

平薪/10%涨幅

driver端内存划分，Executor端内存划分；driver内存使用。 排查方法，代码自动debug的方法

Java调优指令

SpingBoot的优势

>  1227完成在线测评

月base? 总包会平摊到多少月？

五险一公积金缴存比例？

有晋升路线吗？

餐补等福利？



通过一些资料以及咨询了一下我的同事，对咱们公司也有个大概的解了，从我的到的消息来看，对于一个7年的硕士来说，年包35确实低了，一般硕5能拿到40。

在你之前其他面试都被我推了，感觉你比较爽快，我顶着发烧接了这个面试，我们算是有缘的，我一定要拿到这个机会， 我还是希望跟您好好谈一谈，要说我现在的待遇，31是最低包，每年有晋升机会。 我期望年包38，这个涨幅只有15%；

31w的基础20%的涨幅，37w

二面准备：

1. 对民生科技的理解，为什么选择民生科技

​        武汉研发中心这边刚刚成立，现在处于快速扩张期，接下来一定会有很多的事情，我觉得这是一个机会；同时本人换工作是非常谨慎的，在当前这个大环境下， 我也希望下家公司是稳定靠谱的，所以我希望这个时候加入，与公司共同成长。

性格测评挂了        



伴伴：

伴伴大数据组件：hive、spark、flink、clickhouse 等，偏上层一些

看中大数据组件了解的深入度和广度

先是问项目，然后问了一些组件和 java 方面的

问的 flink、数据方面的底层原理、业务场景

Flink 建模





## 立得1223：

spark 与Flink各有什么特点？有什么区别？ spark的持久化机制，kafka

spark调优经验：

要做数据中台，但目前就一个大数据开发，预计半年扩到5-6个人； 非结构化数据。 后序有笔试：sql+大数据框架概念

1226:一面通过，发笔试链接

 问题: springboot与spring有什么优势？

0105二面

HBase二级索引、平台、OneID

> 1. 自定义负载均衡算法，以startRowKey为分组依据，把IndexTable的Region与数据表的Region分配到同一个节点上，会不会导致负载不均衡？不会，索引Region和数据Region是一一对应的，数据表Region的负载均衡我们不干预，只要数据表Region是均衡的，索引表自然就均衡(一一对应且是局部索引)
> 2. 数据写入流程
> 3. 宕机容错

0110三面



## 腾讯地图

1226: 7-8分

1. 业务理解、表达能力欠缺
2. 简历需要更加丰富

1229号二面：
[删除链表重复元素](https://blog.csdn.net/duan20140614/article/details/125722684)

多线程操作syschronize方法，后台线程； 二叉树遍历、递归/非递归两种版本

0109

996190522

项目难点、项目优化方法、数仓分层理论    

8点后有18元加班餐，免费停车，班车



高级工程师1    对标集团9级  23.5k   年包32.9w



数据工程：大数据开发

江夏区腾讯大厦

高1:

23.5k 保底2个月年终

福利：6险一金，全额12%公积金，9天年假，其中7+2天春节特别假，2天固定春节前后休，日常7天随意支配，法定5天任意休。7+9=16天

餐补：晚8点后，18元

10点后打车报销

次月5号发工资，年前最后一个工作日，年28发放  

每周三入职，如果15号入职，会交2月份的五险一金

22号入职是否会交2月份的五险一金？





## 拼多多x

两个升序数组中，找到和最小的k个对儿，[每个对儿分别来自两个数组](https://blog.csdn.net/realmagician/article/details/16902927)。

[查找和最小的K对数字(伪暴力法&优先队列)](https://blog.csdn.net/qq_38737428/article/details/122540276?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-122540276-blog-119053057.pc_relevant_3mothn_strategy_recovery&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-122540276-blog-119053057.pc_relevant_3mothn_strategy_recovery&utm_relevant_index=2)



## 容知日新x

1229

> SparkStreaming+Kafka，接收设备日志，进行异常诊断。团队加运维12人

0103

6:00 三段经历，大厂经历。主要问数据量

0106三面HR经理

> 主要聊离职原因，职业规划

0109号反馈：能力认可，但综合对比有更合适的人选，流程先暂停

> 目前已有的offer不要说太多，否则会认为你没有规划，找到哪个是哪个，可以说1到2个                                                                                                        

## 美的：

笔试0103: 

1. 星型模型和雪花模型的区别和应用
2. 数仓分层，各层职责
3. 输出什么？

```java
obj是null
  if obj=null
     System.out.print(true)
  else     
     System.out.print(false)
```

2:00 面试： 武汉是物流团队，30人左右，全国有2-300人， 上班时间9:00-6:00 制造业公司。







## 金山云(没有hc):

0104

1. 催促光谷人工智能研究院，院长

2. 催促民生科技二面

3. 催促小红书安排一面 x

4. 金山云一面

   > 8大 组100多号人， 调度组、离线计算、实时计算组。。  明年搬到光谷天地逐渐超过北京。 主要关注我在绿盟带人的经验，spark源码修改的经验。
   >
   > 蔡想面的早，金山云问了我职级低原因，蔡想:因为组织调整的原因。

0106二面

1. 项目
2. 数据接入流程
3. synchronize在静态方法和普通方法上的区别
4. 双亲委派模型
5. 任务调度系统
6. 持续集成的了解
7. Join的优化
8. Flink的反压机制
8. 十亿数据TopN方式：

0109 临时沟通，15薪 300餐补，五险一金全额缴，早10晚7，涨幅可能没那么高

> 蔡想2面技术面已发offer，涨幅10%左右(29k左右?)
>
> 预约10号下午3点，大数据负责人终面：一二面面试官的领导



2月2号

面试没问题，组内没有hc了

## 小红书(x)

0106一面

```sql
现在有一张用户下单明细记录表（包含30天的用户下单数据）
dwd_ord_detail_df
(
uid string comment '用户ID', 
oid string comment '订单ID', 
dtm string comment '下单时间，格式：YYYY-MM-DD HH:mm:ss'
)
求每个用户的最长连续下单天数
要求：
1、考虑多段连续下单的场景
2、过滤掉非连续多天下单用户
3、函数名如果忘记，可以随便写一个代替，最后解释一下即可
4、请直接在题目下方写出实现SQL

with t as (
select uid, date_sub(order_date,rn) as diff
from (
select uid,oid,dtm,row_number()over(partition by uid order by dtm) as rn,
	date(dtm) order_date from dwd_ord_detail_df
))
select uid,diff, count(1)cnt from t group by uid,diff 
having cnt>1 ;


with t as (
select 
uid,order_date, row_number()over(partition by uid order by order_date) as rn
  from 
(select uid,date(dtm)order_date from dwd_ord_detail_df group by  uid,date(dtm))-- 去重
),
a as (
select uid,date_sub(order_date,rn) as diff  from t -- 连续日期的开始日期 
),
b as (select uid,diff , count(1) cnt from a group by uid,diff having cnt>1)
select uid,max(cnt) from b group by uid;
```



kyuubi

## 光谷人工智能研究院(年后开始)

## ali

### 一面

视频云

1. java多线程

2. volatile

3. final\finalize\finally

   1.final是一个关键字，如果我们用final来修饰属性的话，**属性不可以改变**，所以被final修饰的属性必须在声明的时候设置一个初始值，在之后需要用到的地方只能读取该值，不能对该属性做出改变，**final修饰方法的话，方法可以被使用，但是不能被重写，final修饰类的话，类不能被继承**，也就是说该类不能有子类，所以我们不能final来修饰一个抽象类。

   2.finally是java的异常处理机制，我们经常会将finally语句放在try...catch...语句后面作为一种补充，因为finally语句不管代码有没有异常都会执行，这样我们可以用finally语句维护对象内部状态，清理非内存操作，例如我们可以使用finally语句来关闭流或者数据库等操作。

   3.finallize方法是java.lang.Object里面定义的，因为Object是所有类的基类，所以我们可以理解为每个对象都有finalize方法，finalize的主要目的是在不可撤销的丢弃对象之前执行清除操作，<font color=red>对于给定的任何对象，java虚拟机最多只调用一次finalize()方法，finalize()方法是垃圾回收器删除对象之前对这个对象调用的。</font>

4. 单例模式饿汉式/懒汉式，volatile的作用
   [参考](https://blog.csdn.net/mqdxiaoxiao/article/details/126564081)
   禁止JVM进行指令重排； Java在new创建对象时，有三条指令:

   - 分配内存空间
   - 初始化对象
   - 变量指向对象

   由于JVM指令重排，可能对象还未初始化就被赋给变量了， 其他线程拿到的是未初始化的对象，导致异常。

5. 关系数据库删除大量数据可能会遇到什么问题？ 

6. 可以利用索引的语句

7. 数据库三范式

8. 说一下spark shuffle优化、group by数据倾斜的处理

9. 说一下flink checkpoint机制

10. 力扣： 链表按k个一组进行翻转

## 中科驭数

### 一面

大数据内核研发工程师 - Spark方向职位

dpu gpu

fgpa可编程核

语言基础面试

scala:

1. case class 特点

   > *本质上case class是个语法糖，对你的类构造参数增加了getter访问，还有toString, hashCode, equals 等方法； 最重要的是帮你实现了一个伴生对象，这个伴生对象里定义了*
   >
   > - apply方法：意味着你不需要使用new关键字就能创建该类对象
   >
   > - unapply方法：可以通过模式匹配获取类属性

2. 伴生类核伴生对象区别，可访问性

   > 和一个类名重名的object称为伴生对象，这个类也称为这个object的伴生类。它们之间可以访问对方的私有成员

Java:

1. synchronize与Lock接口实现的锁之间的区别？
   synchronized关键字，他是Java的内置特性，是基于JVM的实现.Lock接口提供了相对于synchronized关键字，而更为灵活的一种同步手段它的核心与本质仍旧是为了线程的同步与协作通信

   **所以它的核心仍旧是锁与监视器，也就是Lock接口与Condition接口**

   与synchronized再次对比下

   - synchronized是JVM底层实现的，Lock是JDK接口层面的
   - synchronized是隐式的，Lock是显式的，需要手动加锁与解锁
   - synchronized乌无论如何都会释放，即使出现错误，Lock需要自己保障正确释放
   - synchronized是阻塞式的获取锁，Lock可以阻塞获取，可中断，还可以尝试获取，还可以设置超时等待获取
   - synchronized无法判断锁的状态，Lock可以进行判断
   - synchronized可重入，不可中断，非公平，Lock可重入，可中断、可配置公平性（公平和非公平都可以）
   - 如果竞争不激烈，两者的性能是差不多的，可是synchronized的性能还在不断的优化，当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized

   

   1. 锁升级，如果只有一个线程，这个锁是什么状态？

2. ThreadLocal的原理、优点

3. GC的原理

4. 程序很慢如何排查？

   > 检查新生代、老年代配比

一面通过

### 2月7号二面

作业重试机制

> - 如果重试 3 次 依然失败, 那么这个 task 所在的 stage 就失败了
> - 如果 stage 失败了则由 DAGScheduler 来负责重试, 重新发送 TaskSet 到 TaskScheduler, Stage 默认重试 4 次。
> - 如果重试 4 次 以后依然失败, 那么 该 job 就失败了。
> - 一个 job 失败了, Application 就失败了。

spark动态资源：

> 在spark提交作业以后默认是静态资源分配的，如果有些Executor执行完以后，只要job没有结束，它就会一直占用资源，所以我们要根据情况配置动态资源分配
>
> 动态资源分配原理
> 当调度程序检查到有很多的Task是pending状态的时候，那么它就会尝试去申请新的Executor，如果Executor执行完了以后，就会把资源释放掉给其他的Job使用,它是由spark.dynamicAllocation.schedulerBacklogTimeout这个参数设置的，默认1秒就去检查一次，它申请资源的时候是成倍的去申请的，比如第一个1个，第二次2个，第三次4个，当Executor释放的时候，shuffle写出的数据不会在job停止之前删除，但是Executor缓存的 数据会被删除

算法：

对称二叉树判断

两个有序数组merge



offer上base会拆成三部分
位于范悦城，目前武汉300+人

1. 薪资构成，base组成， 年终奖多少？
   13薪
2. 社保公积金如何缴？基数是多少？
3. 晋升机制？调薪机制？
   每一年有一次晋升机制
4. 福利？年假？
5. 餐补？停车位？

33k, 腾讯30



## 武汉联影医疗

124加班，大小周，没加班费, 位于朗诗历程

会成为联影子公司，6台服务器，处理设备传感器数据，进行故障诊断。大数据4个人，部门40人。

> spark提交流程，sparksql优化方法 
>
> scala闭包导致无法序列化问题，如何解决
>
> 广播变量可变嘛？ 如何实现的？

## 数势科技

5月8号一面



# spark

## 优化

1. 并行度优化
   1. 增加executor个数提升并行能力
   2. 增加分区数
2. Join优化
   1. 采用广播器进行Join代替shuffle Join
   2. 让两个RDD共享分区器避免shuffle Join
3. 缓存优化
   1. 公用RDD进行缓存
   2. checkpoint的使用，需要ck的RDD尽量先缓存
4. 算子优化
   1. reduceByKey代替groupByKey
5. 调节数据本地性等待时长

## 数据本地性locality

TaskScheduler在进行分配之前都会计算出 每一个task最优计算位置。Spark的task的分配算法优先将task发布到数据所在的节点上 ，从而达到数据最优计算位置。在spark中共有几种数据本地化级别：
1、PROCESS_LOCAL：数据和计算它的代码在**同一个JVM进程**中。
2、NODE_LOCAL：数据和计算它的代码在**一个节点上**，但是不在一个进程中，比如在不同的executor进程中，或者是数据在HDFS文件的block中。
3、NO_PREF：数据从哪里过来，性能都是一样的。例如，读取mysql数据库
4、RACK_LOCAL：数据和计算它的代码在一个机架上。
5、ANY：数据可能在任意地方，比如其他网络环境内，或者其他机架上

Spark倾向于使用最好的本地化级别来调度task，但是这是不可能的。如果没有任何未处理的数据在空闲的executor上，那么Spark就会放低本地化级别。这时有两个选择：第一，等待，直到executor上的cpu释放出来，那么就分配task过去；第二，立即在任意一个executor上启动一个task。

Spark默认会等待一会儿，来期望task要处理的数据所在的节点上的executor空闲出一个cpu，从而将task分配过去。只要超过了时间，那么Spark就会将task分配到其他任意一个空闲的executor上。

可以设置参数，spark.locality系列参数，来调节Spark等待task可以进行数据本地化的时间。

## ck

<font color=red>需要ck的RDD事先进行缓存，增加ck的速度，因为ck会在正常job执行完成后专门启用一个job进行ck。如果该RDD进行了cache,则ck的job直接读取缓存，从而提升性能。</font>

cache和checkpoint都可以起到减少重复计算的作用。但区别还是比较大的：

1. **目的不同**：缓存的目的是加速计算，ck的目的是作业失败后快速恢复
2. **存储性质和位置不同**：缓存主要食用内存，偶尔食用硬盘；ck主要使用HDFS
3. **写入速度和规则不同**: 缓存较快，对job的执行影响较小，ck写入速度慢，因此启用专门的job进行持久化
4. **对数据血缘的影响不同**： cache如果放到内存，可能会因为节点失败导致分区丢失，还是需要重新计算，这样就必须保留血缘。而checkpoint是把rdd写入文件系统了，节点失败也不会导致重算，因此是直接切断了血缘。
5. **应用场景不同**： 缓存适合多次读取、占用空间不是非常大的RDD，ck适用于依赖关系比较复杂、重算代价高的RDD。
6. cache即使使用persist(StorageLevel.DISK_ONLY) 与 checkpoint 也有区别。前者虽然可以将 RDD 的 partition 持久化到磁盘，但该 partition 由 blockManager 管理。一旦 driver program 执行结束，也就是 executor 所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，被 cache 到磁盘上的 RDD 也会被清空（整个 blockManager 使用的 local 文件夹被删除）。 但是checkpoint的内容以被下一个 driver program 使用。







# todo

## 华为

[华为机试](https://mubu.com/doc/3WWrSTVxCa4)



阿里

腾讯

微派网络

蚂蚁金服

字节跳动





中国电子云  系统  周四下午3点
